{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dramatic-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from shapely.geometry import Polygon, LineString, Point, MultiPolygon, MultiLineString, MultiPoint\n",
    "import shapely\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-viking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO's:\n",
    "#  - first\n",
    "# in the discet osm class every geometrie is build from the nodes up when querried\n",
    "# this is resource intensive espacily because geometries in osm tend to be reused\n",
    "# so in future when a geometrie was build it will be saved back in build form\n",
    "# to the dataframe this will be more memory intensive but i think it is worth the trade of\n",
    "# - second\n",
    "# I want to make the disection multithread able espacialy in context of the first\n",
    "# todo this would I think immensily speed up the proccesing of the osm data\n",
    "# the dataframe could be the common data storage for all threads\n",
    "# and if one of the threads has solved a geomtry and stored it back in the dataframe\n",
    "# the other threads can retrieve it and don't even need to solve it themselfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quantitative-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "overpass_url = \"http://overpass-api.de/api/interpreter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dominican-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_querry_poly(poly):\n",
    "    # this function takes a shapely polygon and makes\n",
    "    # an overpass filter polygon out of it\n",
    "    # for the querry we will only support simple polygon\n",
    "    # - no multipolygons and \n",
    "    # - no inner rings\n",
    "    # because overpass does not support it\n",
    "    # https://wiki.openstreetmap.org/wiki/Overpass_API/Overpass_QL#By_polygon_.28poly.29\n",
    "    \n",
    "    #test if polygon conforms\n",
    "    assert isinstance(poly, shapely.geometry.polygon.Polygon), f'polygon is of {type(poly)} only shapely.geometry.polygon.Polygon is supported'\n",
    "    assert not list(poly.interiors), 'polygon has inner rings this is not supported by overpass filters' \n",
    "    \n",
    "    #simplyfy polygon if down to 101 cordinate pairs complex\n",
    "    while len(list(poly.exterior.coords)) >= 101:\n",
    "        # 0.1 is quite aggressive maybe 0.01 also works\n",
    "        poly = poly.simplify(0.1, preserve_topology=True)\n",
    "    \n",
    "    # extracts the exterior coords and puts them into a string\n",
    "    poly_string = ' '.join([f'{lat:.6f} {lon:.6f}' for lat,lon in list(poly.exterior.coords)])\n",
    "    \n",
    "    return poly_string\n",
    "\n",
    "\n",
    "def json_from_osm(poly, mode='nwr', key=None, value=None, operand='='):\n",
    "    \n",
    "    kv_filter = ''\n",
    "    if key:\n",
    "        kv_filter = f'[\"{key}\"]'\n",
    "    if value:\n",
    "        assert key, \"you can't pass a value without a key\"\n",
    "        kv_filter = f'{kv_filter[:-1]}{operand}\"{value}\"]'\n",
    "\n",
    "    query = f'''\n",
    "            [out:json][timeout:25];\n",
    "            (\n",
    "              {mode}{kv_filter}(poly:\"{generate_querry_poly(poly)}\");\n",
    "            );\n",
    "            out body;\n",
    "            >;\n",
    "            out skel qt;\n",
    "            '''\n",
    "    \n",
    "    respones = requests.get(overpass_url, params={'data': query})\n",
    "    \n",
    "    assert respones.ok, respones.text\n",
    "\n",
    "    return respones.json()\n",
    "\n",
    "\n",
    "class disect_osm:\n",
    "    # when parsing osm data there exists a hugh issue with relations \n",
    "    # because they can contain multiple differnt kinds of geometries \n",
    "    # like polygons, lines, and points in the same thing they can even contain other\n",
    "    # relations that then again contain different types of geometries\n",
    "    # most osm parsers fail here\n",
    "    # so my idea is to split every relation into its most basic components\n",
    "    # so we get all features of relation a grouped by geometries type togehter \n",
    "    # with all the tags of realtion the relation\n",
    "    # for this i need to drill done every relation until I hit the the basic geometries\n",
    "    # points lines polygons and special case multiploygon\n",
    "    \n",
    "    def __init__(self, osm_json):\n",
    "        self.osm_json = osm_json\n",
    "        self._parse_osm_json()\n",
    "    \n",
    "    def generate_geometry(self, f_type, osmid):\n",
    "        # osmid within a feautre type are unique\n",
    "        # but its possible that there is a node relation and way with id 467\n",
    "\n",
    "        # select the feature in question from the df\n",
    "        try:\n",
    "            # recusion does some times fail when the feature refference wasn't retrieved\n",
    "            feature = self.feature_df[(self.feature_df['type']==f_type) & (self.feature_df['id']==osmid)].iloc[0]\n",
    "        except:\n",
    "            f_type = None\n",
    "            geometry = None\n",
    "            \n",
    "        if f_type == 'node':\n",
    "            geometry = {'point':feature['geometry']}\n",
    "        \n",
    "        if f_type == 'way':\n",
    "            geometry = self._solve_ways(feature['geometry'])\n",
    "        \n",
    "        if f_type == 'relation':\n",
    "            if feature['tags']['type'] == 'multipolygon':\n",
    "                geometry = self._solve_relations_multipolygon(feature['geometry'])\n",
    "            else:\n",
    "                geometry = self._solve_relations(feature['geometry']) \n",
    "        \n",
    "        return geometry\n",
    "    \n",
    "    def _parse_osm_json(self,):\n",
    "        self.feature_list = []\n",
    "    \n",
    "        for element in self.osm_json['elements']:\n",
    "\n",
    "            if element['type'] == 'node':\n",
    "                self.feature = [element['type'],element['id'],Point(element['lon'],element['lat']),]\n",
    "\n",
    "            elif element['type'] == 'way':\n",
    "                self.feature = [element['type'],element['id'],element['nodes'],]\n",
    "\n",
    "            elif element['type'] == 'relation':\n",
    "                self.feature = [element['type'],element['id'],element['members'],]\n",
    "\n",
    "            #not all elements have tags\n",
    "            try:\n",
    "                self.feature.append(element['tags'])                        \n",
    "            except:\n",
    "                self.feature.append(None) \n",
    "\n",
    "            self.feature_list.append(self.feature)\n",
    "\n",
    "        self.feature_df = pd.DataFrame(self.feature_list,columns=['type','id','geometry','tags'])\n",
    "    \n",
    "    def _solve_ways(self, node_list):\n",
    "        \n",
    "        point_geometries = [self.generate_geometry('node',node_id)['point'] for node_id in node_list]\n",
    "        \n",
    "        # its faster to filter None later rather than in the comprehension above\n",
    "        # otherwise I would querry the dataframe twice for one node    \n",
    "        point_geometries = [geom for geom in point_geometries if geom]\n",
    "        \n",
    "        # its a polygon if first and last element are the same\n",
    "        if node_list[0] == node_list[-1]:\n",
    "            temp_poly = Polygon(point_geometries)\n",
    "\n",
    "            # simple fix for invalid polygons\n",
    "            if not temp_poly.is_valid:\n",
    "                temp_poly = temp_poly.buffer(0)\n",
    "            \n",
    "            geom = {'polygon':temp_poly} \n",
    "        \n",
    "        else:\n",
    "            geom = {'line':LineString(point_geometries)}\n",
    "            \n",
    "        return geom\n",
    "    \n",
    "    def _solve_relations(self, member_list):\n",
    "        geom = {'multipoint':[],\n",
    "                'mulitline':[],\n",
    "                'mulitpolygon':[]}\n",
    "        \n",
    "        for member in member_list:\n",
    "            member_geom = self.generate_geometry(member['type'],member['ref'])\n",
    "            \n",
    "            if member_geom == None:\n",
    "                # if no geometrie for this member can be found we skip it\n",
    "                continue\n",
    "            \n",
    "            # since a member can also be a relation it can have multiple \n",
    "            # geometry types\n",
    "            for geom_type in member_geom:\n",
    "                if geom_type == 'point':\n",
    "                    geom['multipoint'].append(member_geom[geom_type])\n",
    "                if geom_type == 'multipoint':\n",
    "                    # multi features need to split to be later be put togehter again\n",
    "                    [geom['multipoint'].append(point) for point in list(member_geom[geom_type])]      \n",
    "                \n",
    "                if geom_type == 'line':\n",
    "                    geom['mulitline'].append(member_geom[geom_type])\n",
    "                if geom_type == 'mulitline':\n",
    "                    # multi features need to split to be later be put togehter again\n",
    "                    [geom['mulitline'].append(point) for point in list(member_geom[geom_type])]    \n",
    "                \n",
    "                if geom_type == 'polygon':\n",
    "                    geom['mulitpolygon'].append(member_geom[geom_type])\n",
    "                if geom_type == 'mulitpolygon':\n",
    "                    # multi features need to split to be later be put togehter again\n",
    "                    [geom['mulitpolygon'].append(point) for point in list(member_geom[geom_type])] \n",
    "                    \n",
    "        geom_transform_func = {'multipoint':MultiPoint,\n",
    "                               'mulitline':MultiLineString,\n",
    "                               'mulitpolygon':MultiPolygon,}\n",
    "        keys_to_delete = []\n",
    "        for geom_type in geom:\n",
    "            if geom[geom_type]:\n",
    "                geom[geom_type] = geom_transform_func[geom_type](geom[geom_type])\n",
    "            else:\n",
    "                keys_to_delete.append(geom_type)\n",
    "        \n",
    "        for key in keys_to_delete:\n",
    "            del geom[key]\n",
    "        \n",
    "        return geom\n",
    "   \n",
    "    def _solve_relations_multipolygon(self, member_list):\n",
    "        # osm has special mulitpolygon rules\n",
    "        # all the things that have an inner and an outer border are\n",
    "        # multipolygons represented as relations\n",
    "        # https://wiki.openstreetmap.org/wiki/Relation:multipolygon\n",
    "        # this function strictly folows the documentation\n",
    "        # i.e. it ignores points, other relations and incorrectly tagged ways\n",
    "        \n",
    "        # since not self-closed ways can be part of an multipolygon in osm\n",
    "        # but shapely does not like that we are also closing all polygons\n",
    "        member_dict = {'inner':[],'outer':[]}\n",
    "        \n",
    "        for member in member_list:\n",
    "            member_dict[member['role']].append(member['ref'])\n",
    "            \n",
    "        unclosed_ways = []\n",
    "        member_node_dict = {'inner':[],'outer':[]}\n",
    "        member_geom_dict = {'inner':[],'outer':[]}\n",
    "        # find and merge inner and outer unclosed ways\n",
    "        \n",
    "        for key in member_node_dict:\n",
    "            for way_id in member_dict[key]:\n",
    "                # this gets us the list of node ids a way consinsts of \n",
    "                way_nodes = self.feature_df[(self.feature_df['type']=='way') & (self.feature_df['id']==way_id)].iloc[0]['geometry']\n",
    "                \n",
    "                if not way_nodes[0] == way_nodes[-1]:\n",
    "                    unclosed_ways.append(way_nodes)\n",
    "                else:\n",
    "                    member_node_dict[key].append(way_nodes)\n",
    "\n",
    "                if unclosed_ways:\n",
    "                    # if unclosed ways exist try to merge them\n",
    "                    member_node_dict[key] += self._close_ways(unclosed_ways)\n",
    "\n",
    "            # now we make polygons out of all the ways\n",
    "            # complex list comprehesion ahead!\n",
    "            # we itterate once over all node list and the indivdualy over all \n",
    "            # node_ids to get the geometry for each\n",
    "            \n",
    "            \n",
    "            for node_list in member_node_dict[key]:\n",
    "                _tmp_list = [self.generate_geometry('node',node_id)['point'] for node_id in node_list]\n",
    "                # its faster to filter None later rather than in the comprehension above\n",
    "                # otherwise I would querry the dataframe twice for one node    \n",
    "                _tmp_list = [geom for geom in _tmp_list if geom]\n",
    "\n",
    "                member_geom_dict[key].append(Polygon(_tmp_list))\n",
    "            \n",
    "        # now lastly we have to solve which polygon is the inner to which outer polygon\n",
    "        multi_poly = self._solve_inner_outer(member_geom_dict)\n",
    "        \n",
    "        return {'mulitpolygon':multi_poly}\n",
    "    \n",
    "    def _close_ways(self,unclosed_ways):\n",
    "        closed_ways = []\n",
    "\n",
    "        while unclosed_ways:\n",
    "            way = unclosed_ways.pop()\n",
    "\n",
    "            # we pop up a way an try to merge it with any other of the ways\n",
    "            for match_way in unclosed_ways:\n",
    "                if way[-1] == match_way[0]:\n",
    "                    # if they are a match we merge them and \n",
    "                    # remove the copy of the matched way\n",
    "                    way = way[:-1] + match_way\n",
    "                    unclosed_ways.remove(match_way)\n",
    "                    break\n",
    "            # if the way now is closed it goes into the closed way list\n",
    "            if way[0] == way[-1]:\n",
    "                closed_ways.append(way)\n",
    "\n",
    "            # if not back into the pool of unclosed ways\n",
    "            else:\n",
    "                unclosed_ways.insert(0,way)\n",
    "\n",
    "            # if something goes wrong and only one way is left in here\n",
    "            # we break the loop \n",
    "            # this should not happen but osm data is wobbly\n",
    "            if len(unclosed_ways) == 1:\n",
    "                break\n",
    "\n",
    "        return closed_ways\n",
    "    \n",
    "    def _solve_inner_outer(self,geom_dict):\n",
    "        \n",
    "        solved_polys = {}\n",
    "        multi_list = []\n",
    "        # first we calculate the are for each of the outer polygons\n",
    "        # then sort them by size smalles first\n",
    "        # the idea is that an inner ring the innering to \n",
    "        # the smallest possible outer polygon is that it is containt within\n",
    "        outer_list = [(i,feature,feature.area) for i, feature in enumerate(geom_dict['outer'])]\n",
    "        outer_list.sort(key=lambda tup: tup[2])\n",
    "        \n",
    "        for i,feature,area in outer_list:\n",
    "            solved_polys[i] = {}\n",
    "            solved_polys[i]['outer'] = feature\n",
    "            solved_polys[i]['inner'] = []\n",
    "        \n",
    "        # here we itterate over all inner features and match them with an outer feature\n",
    "        for inner_feature in geom_dict['inner']:\n",
    "            for i,outer_feature,area in outer_list:\n",
    "                if outer_feature.contains(inner_feature):\n",
    "                    solved_polys[i]['inner'].append(inner_feature)\n",
    "\n",
    "                    \n",
    "        # lastly we make shapely single polygons out of all of them \n",
    "        for i in solved_polys:\n",
    "            multi_list.append(Polygon(solved_polys[i]['outer'].exterior.coords,\n",
    "                                      [inner_feature.exterior.coords for inner_feature in solved_polys[i]['inner']]))\n",
    "\n",
    "        return MultiPolygon(multi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "driven-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_poly = Polygon([(52.450425727741,13.286182880402),(52.458323725344,13.286182880402),(52.458323725344,13.299744129181),(52.450425727741,13.299744129181)])\n",
    "osm_json = json_from_osm(q_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "powered-stress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"13.232541976 52.434749176 0.2250213479999985 0.07882764800000075\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,104.948326)\"><g><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.2409772,52.4430833 L 13.2416427,52.4435585 L 13.2419577,52.443788 L 13.2421767,52.4439332 L 13.242156,52.4439502 L 13.2421308,52.4439715 L 13.2418774,52.443834 L 13.2416886,52.4437138 L 13.2408761,52.4431355 L 13.240926,52.4431098 L 13.2409772,52.4430833 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.2538184,52.4501337 L 13.253844,52.4500976 L 13.2538766,52.4500633 L 13.2523433,52.4495924 L 13.2523235,52.449613 L 13.2523012,52.449641 L 13.2522782,52.4496681 L 13.2526998,52.4498135 L 13.2532557,52.4499832 L 13.2538184,52.4501337 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.2695838,52.4502846 L 13.2695873,52.4503115 L 13.2695901,52.4503294 L 13.2695933,52.4503558 L 13.2690713,52.450391 L 13.2687095,52.450414 L 13.2683496,52.4504378 L 13.2679786,52.4504547 L 13.2679701,52.4504006 L 13.2683353,52.4503672 L 13.2687019,52.4503431 L 13.2690583,52.4503198 L 13.2695838,52.4502846 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.2809325,52.4507357 L 13.2815104,52.4509833 L 13.2823096,52.4513231 L 13.282342,52.4512949 L 13.2823669,52.4512732 L 13.2818433,52.4510377 L 13.2809918,52.4506843 L 13.2809636,52.4507088 L 13.2809325,52.4507357 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.2898145,52.4575771 L 13.2897541,52.4575138 L 13.2895363,52.4572732 L 13.2894029,52.4571317 L 13.2892513,52.4569643 L 13.2891462,52.4568375 L 13.2890474,52.4567115 L 13.2891017,52.4566919 L 13.2892778,52.4568619 L 13.2894239,52.4570125 L 13.2894991,52.4570981 L 13.2896902,52.4573203 L 13.2898347,52.4574858 L 13.2898903,52.4575513 L 13.2898567,52.4575634 L 13.2898145,52.4575771 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.2948815,52.4637564 L 13.2962773,52.4642503 L 13.2962439,52.464287 L 13.2962203,52.4643114 L 13.2951822,52.4639372 L 13.2948403,52.4637918 L 13.2948815,52.4637564 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.3081265,52.4666619 L 13.3086887,52.4669715 L 13.3088523,52.4670616 L 13.3094407,52.4673856 L 13.309452,52.4673781 L 13.309479,52.4673599 L 13.3095045,52.4673427 L 13.3095139,52.4673364 L 13.3089258,52.4670125 L 13.3087613,52.4669218 L 13.3081997,52.4666126 L 13.3081894,52.4666195 L 13.3081627,52.4666375 L 13.3081354,52.4666559 L 13.3081265,52.4666619 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.3144108,52.4739471 L 13.3144293,52.4739467 L 13.3144326,52.4740003 L 13.3144621,52.4739996 L 13.3144932,52.4739989 L 13.3144898,52.4739454 L 13.3145133,52.4739449 L 13.3144427,52.472807 L 13.3144226,52.4728075 L 13.3144181,52.4727343 L 13.3143869,52.472735 L 13.3143557,52.4727357 L 13.3143602,52.4728088 L 13.3143401,52.4728092 L 13.3144108,52.4739471 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.3132932,52.480672 L 13.3133337,52.4806663 L 13.3133761,52.4806604 L 13.3133992,52.4806576 L 13.3133968,52.4806465 L 13.3133633,52.4805386 L 13.3133314,52.4804543 L 13.3132907,52.4803568 L 13.313255,52.4802793 L 13.3131908,52.4801595 L 13.3131299,52.4800601 L 13.3130693,52.4799698 L 13.3130003,52.4798673 L 13.3128031,52.4795641 L 13.3127808,52.4795693 L 13.3127216,52.4795829 L 13.3126949,52.479589 L 13.3126834,52.4795904 L 13.313077,52.4802 L 13.3131463,52.4803223 L 13.3131843,52.4803944 L 13.3132281,52.4804932 L 13.3132787,52.4806244 L 13.3132932,52.480672 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.3161749,52.4910912 L 13.3162155,52.4910503 L 13.3162534,52.4910111 L 13.3161209,52.4909605 L 13.3159756,52.490902 L 13.3158449,52.4908451 L 13.3157005,52.4907774 L 13.3155825,52.4907184 L 13.3154426,52.4906443 L 13.3152875,52.4905529 L 13.315089,52.490421 L 13.3147746,52.4901941 L 13.3145184,52.4899309 L 13.3143923,52.4899716 L 13.3145099,52.4901137 L 13.3146876,52.4902871 L 13.3147885,52.4903636 L 13.3149202,52.4904583 L 13.3150002,52.4905129 L 13.3151007,52.4905802 L 13.3152464,52.4906722 L 13.3154043,52.4907579 L 13.3155507,52.4908314 L 13.3157658,52.49093 L 13.3159751,52.491016 L 13.3161749,52.4910912 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.32403,52.4938665 L 13.3240365,52.4938601 L 13.324017,52.4938528 L 13.3240347,52.4938352 L 13.3240523,52.4938177 L 13.3240718,52.493825 L 13.3240979,52.4937991 L 13.3241691,52.4938195 L 13.3244167,52.4939108 L 13.3258083,52.4944238 L 13.3257781,52.4944535 L 13.3257409,52.4944895 L 13.3253991,52.4943682 L 13.3243445,52.4939817 L 13.32403,52.4938665 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.3369513,52.5008464 L 13.3370406,52.5008138 L 13.3371266,52.5007753 L 13.337078,52.5007304 L 13.3369577,52.5007776 L 13.336956,52.5007758 L 13.3369458,52.5007662 L 13.3369286,52.50075 L 13.3368717,52.5006961 L 13.3368538,52.5007 L 13.3366278,52.500484 L 13.3366626,52.5004704 L 13.3364688,52.5002858 L 13.3364339,52.5002993 L 13.3361159,52.4999829 L 13.3361398,52.499973 L 13.3360084,52.4998476 L 13.3359663,52.4998463 L 13.3359232,52.4998454 L 13.3359805,52.4999017 L 13.3368911,52.5007877 L 13.3369513,52.5008464 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.3425974,52.5018659 L 13.3428146,52.5018166 L 13.3431134,52.5017536 L 13.3434646,52.501681 L 13.3437857,52.5016153 L 13.3437557,52.5015585 L 13.3434275,52.5016125 L 13.3430753,52.5016851 L 13.3427755,52.5017509 L 13.3425515,52.5018013 L 13.3420928,52.5019336 L 13.3421416,52.5019924 L 13.3425974,52.5018659 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.3536857,52.4996393 L 13.3545512,52.4998214 L 13.3546316,52.4998406 L 13.3547099,52.4998631 L 13.3547546,52.4998779 L 13.3551946,52.5000232 L 13.3551283,52.5000981 L 13.354695,52.4999532 L 13.3543688,52.4998536 L 13.3542132,52.4998111 L 13.3536491,52.4997062 L 13.3536857,52.4996393 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.3607465,52.5003547 L 13.3622022,52.4999361 L 13.3621947,52.4999254 L 13.36218,52.4999052 L 13.3621653,52.4998837 L 13.3621576,52.4998728 L 13.360699,52.5002909 L 13.3607083,52.5003034 L 13.3607146,52.5003115 L 13.3607209,52.5003196 L 13.3607465,52.5003547 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.3732978,52.4995647 L 13.3732884,52.4995131 L 13.3735154,52.4994908 L 13.3739506,52.4994491 L 13.3741419,52.499437 L 13.3742835,52.4994335 L 13.374416,52.4994332 L 13.3746891,52.4994442 L 13.3747949,52.4994481 L 13.3748027,52.4995408 L 13.3745601,52.4995455 L 13.3742403,52.4995503 L 13.3739591,52.4995534 L 13.3732978,52.4995647 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.3834448,52.4990906 L 13.3835479,52.4990858 L 13.3835433,52.4990558 L 13.3833138,52.4990523 L 13.3830877,52.4990508 L 13.3830153,52.4990497 L 13.3829341,52.4990494 L 13.3827565,52.4990426 L 13.3825698,52.499029 L 13.3822456,52.4990044 L 13.3820855,52.4989942 L 13.381897,52.4989896 L 13.3818889,52.4990159 L 13.3819371,52.4990208 L 13.3821266,52.4990398 L 13.3823174,52.4990576 L 13.3825508,52.4990734 L 13.3827399,52.4990835 L 13.382888,52.4990882 L 13.383014,52.4990907 L 13.3831712,52.4990927 L 13.3833088,52.4990936 L 13.3834448,52.4990906 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.3895299,52.4978266 L 13.3895417,52.4978579 L 13.3899563,52.4977979 L 13.3904093,52.4977475 L 13.3907334,52.4977324 L 13.3909416,52.4977283 L 13.3911064,52.4977252 L 13.3912021,52.4977272 L 13.3912539,52.4977286 L 13.391255,52.4977035 L 13.3912557,52.4976913 L 13.3911853,52.4976904 L 13.3911058,52.4976904 L 13.3909449,52.4976923 L 13.3909445,52.4976784 L 13.3907142,52.4976825 L 13.3907155,52.497698 L 13.3903967,52.4977125 L 13.3899511,52.4977646 L 13.3895299,52.4978266 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.4063648,52.4983715 L 13.4062982,52.4983408 L 13.4062637,52.4983407 L 13.4045188,52.498329 L 13.4044382,52.4983581 L 13.4053974,52.4983639 L 13.4063648,52.4983715 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.4290393,52.4992979 L 13.4284013,52.499262 L 13.4275208,52.4992059 L 13.4275237,52.4991882 L 13.427525,52.499183 L 13.4286772,52.4992535 L 13.4286894,52.4992663 L 13.4290357,52.4992814 L 13.4290393,52.4992979 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.4419338,52.5009685 L 13.4419489,52.5009592 L 13.4418087,52.5008642 L 13.4417871,52.5008772 L 13.4415701,52.5008008 L 13.44141,52.5007477 L 13.4412968,52.5007196 L 13.4411834,52.5006911 L 13.4411428,52.5006845 L 13.441066,52.5006719 L 13.4408952,52.500648 L 13.4404159,52.5005775 L 13.4404056,52.5006052 L 13.4409502,52.5006832 L 13.4411398,52.5007167 L 13.4413168,52.500757 L 13.4417065,52.5008841 L 13.4419338,52.5009685 z\" /><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00450042695999997\" opacity=\"0.6\" d=\"M 13.4492292,52.5052116 L 13.4489065,52.5047966 L 13.4487196,52.5045816 L 13.4486033,52.5044551 L 13.4483789,52.5042275 L 13.4483462,52.5042376 L 13.4485488,52.5044925 L 13.4488064,52.5048337 L 13.4490193,52.5051139 L 13.4491166,52.5052427 L 13.4491935,52.5052215 L 13.4492292,52.5052116 z\" /></g></g></svg>"
      ],
      "text/plain": [
       "<shapely.geometry.multipolygon.MultiPolygon at 0x7f76d9df5070>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =  disect_osm(osm_json)\n",
    "test_multi = test.generate_geometry('relation',2669207)\n",
    "test_multi['mulitpolygon']\n",
    "#df[(df['type']=='way') & (df['id']==23045210)].iloc[0]['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "going-snapshot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb531fa82a947df83b75fbbb1b841cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[52.480674244638806, 13.326871945318803], controls=(ZoomControl(options=['position', 'zoom_in_text'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipyleaflet\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles,GeoJSON, WKTLayer\n",
    "\n",
    "geom_in_question = test.generate_geometry('relation',2669207)['mulitpolygon']\n",
    "\n",
    "m = Map(\n",
    "    basemap=basemaps.CartoDB.Positron,\n",
    "    # for some reason lat lon are switch for centering the map\n",
    "    center=(geom_in_question.centroid.coords[0][1],geom_in_question.centroid.coords[0][0]),\n",
    "    zoom=14\n",
    ")\n",
    "\n",
    "# polygon = ipyleaflet.Polygon(\n",
    "#     locations= [\n",
    "#         list(poly.exterior.coords)\n",
    "#     ],\n",
    "#     color=\"green\",\n",
    "#     fill_color=\"green\"\n",
    "# )\n",
    "# m.add_layer(polygon)\n",
    "\n",
    "wlayer = WKTLayer(\n",
    "    wkt_string=geom_in_question.wkt,\n",
    "    #hover_style={\"fillColor\": \"red\"},\n",
    "    fill_color=\"red\",\n",
    "    color=\"red\",\n",
    ")\n",
    "m.add_layer(wlayer)\n",
    "\n",
    "# geo_json = GeoJSON(\n",
    "#     data=geojson_from_osm(poly,key='amenity',value='university'),\n",
    "#     color=\"red\",\n",
    "#     fill_color=\"red\"\n",
    "# )\n",
    "\n",
    "# m.add_layer(geo_json)\n",
    "\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "excellent-dominican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colour': '#15AC99',\n",
       " 'from': 'U Krumme Lanke',\n",
       " 'interval': '5',\n",
       " 'name': 'U3: U Krumme Lanke => S+U Warschauer Straße',\n",
       " 'network': 'Verkehrsverbund Berlin-Brandenburg',\n",
       " 'network:metro': 'u-bahn',\n",
       " 'network:short': 'VBB',\n",
       " 'operator': 'Berliner Verkehrsbetriebe',\n",
       " 'operator:short': 'BVG',\n",
       " 'public_transport:version': '2',\n",
       " 'ref': 'U3',\n",
       " 'route': 'subway',\n",
       " 'to': 'S+U Warschauer Straße',\n",
       " 'type': 'route'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.feature_df[test.feature_df['id'] == 2669207]['tags'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in test.feature_df[test.feature_df['type'] == 'relation'].iterrows():\n",
    "    print(row[1]['id'])\n",
    "    print(test.generate_geometry('relation',row[1]['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-dispute",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
