{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "american-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from shapely.geometry import Polygon, LineString, Point, MultiPolygon, MultiLineString, MultiPoint\n",
    "import shapely\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "moved-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO's:\n",
    "# - second\n",
    "# I want to make the disection multithread able espacialy in context of the first\n",
    "# todo this would I think immensily speed up the proccesing of the osm data\n",
    "# the dataframe could be the common data storage for all threads\n",
    "# and if one of the threads has solved a geomtry and stored it back in the dataframe\n",
    "# the other threads can retrieve it and don't even need to solve it themselfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "small-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "overpass_url = \"http://overpass-api.de/api/interpreter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "divided-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_querry_poly(poly):\n",
    "    # this function takes a shapely polygon and makes\n",
    "    # an overpass filter polygon out of it\n",
    "    # for the querry we will only support simple polygon\n",
    "    # - no multipolygons and \n",
    "    # - no inner rings\n",
    "    # because overpass does not support it\n",
    "    # https://wiki.openstreetmap.org/wiki/Overpass_API/Overpass_QL#By_polygon_.28poly.29\n",
    "    \n",
    "    #test if polygon conforms\n",
    "    assert isinstance(poly, shapely.geometry.polygon.Polygon), f'polygon is of {type(poly)} only shapely.geometry.polygon.Polygon is supported'\n",
    "    assert not list(poly.interiors), 'polygon has inner rings this is not supported by overpass filters' \n",
    "    \n",
    "    #simplyfy polygon if down to 101 cordinate pairs complex\n",
    "    while len(list(poly.exterior.coords)) >= 101:\n",
    "        # 0.1 is quite aggressive maybe 0.01 also works\n",
    "        poly = poly.simplify(0.1, preserve_topology=True)\n",
    "    \n",
    "    # extracts the exterior coords and puts them into a string\n",
    "    poly_string = ' '.join([f'{lat:.6f} {lon:.6f}' for lon,lat in list(poly.exterior.coords)])\n",
    "    \n",
    "    return poly_string\n",
    "\n",
    "\n",
    "def json_from_osm(poly, mode='nwr', key=None, value=None, operand='='):\n",
    "    \n",
    "    kv_filter = ''\n",
    "    if key:\n",
    "        kv_filter = f'[\"{key}\"]'\n",
    "    if value:\n",
    "        assert key, \"you can't pass a value without a key\"\n",
    "        kv_filter = f'{kv_filter[:-1]}{operand}\"{value}\"]'\n",
    "\n",
    "    query = f'''\n",
    "            [out:json][timeout:25];\n",
    "            (\n",
    "              {mode}{kv_filter}(poly:\"{generate_querry_poly(poly)}\");\n",
    "            );\n",
    "            out body;\n",
    "            >;\n",
    "            out skel qt;\n",
    "            '''\n",
    "\n",
    "    respones = requests.get(overpass_url, params={'data': query})\n",
    "    \n",
    "    assert respones.ok, respones.text\n",
    "\n",
    "    return respones.json()\n",
    "\n",
    "\n",
    "class disect_osm:\n",
    "    # when parsing osm data there exists a hugh issue with relations \n",
    "    # because they can contain multiple differnt kinds of geometries \n",
    "    # like polygons, lines, and points in the same thing they can even contain other\n",
    "    # relations that then again contain different types of geometries\n",
    "    # most osm parsers fail here\n",
    "    # so my idea is to split every relation into its most basic components\n",
    "    # so we get all features of relation a grouped by geometries type togehter \n",
    "    # with all the tags of realtion the relation\n",
    "    # for this i need to drill done every relation until I hit the the basic geometries\n",
    "    # points lines polygons and special case multiploygon\n",
    "    \n",
    "    def __init__(self, osm_json, cache_nodes=True):\n",
    "        self.osm_json = osm_json\n",
    "        self.cache_nodes = cache_nodes\n",
    "        # these are all the geometrie types features can have, relations can have multiple of those\n",
    "        self.geometry_types = ['point','multipoint','line','multiline','polygon','multipolygon']\n",
    "        self._parse_osm_json()\n",
    "    \n",
    "    def generate_geometry(self, f_type, osmid):\n",
    "        # osmid within a feautre type are unique\n",
    "        # but its possible that there is a node relation and way with id 467\n",
    "        # select the feature in question from the df\n",
    "        try:\n",
    "            # recusion does some times fail when the feature refferenced wasn't retrieved from osm\n",
    "            feature = self.feature_df[(self.feature_df['type']==f_type) & (self.feature_df['id']==osmid)].iloc[0]\n",
    "            geometry = feature['geometry']\n",
    "        except:\n",
    "            f_type = None\n",
    "            geometry = None\n",
    "        \n",
    "        # test if the geometry is already pressent in solved form in the dataframe\n",
    "        # if not we solve it otherwise we return what was fetched\n",
    "        try:\n",
    "            # this is a bit hacky but what it accomplishes is to test if \n",
    "            # geometry is a dictonary and if so it contains on of the geometry keys\n",
    "            # in any other case this throws an exception\n",
    "            if not list(geometry.keys())[0] in self.geometry_types:\n",
    "                raise Exception\n",
    "        \n",
    "        except:\n",
    "            \n",
    "            if f_type == 'node':\n",
    "                geometry = self._solve_node(geometry)\n",
    "\n",
    "            if f_type == 'way':\n",
    "                geometry = self._solve_way(geometry)\n",
    "\n",
    "            if f_type == 'relation':\n",
    "                if feature['tags']['type'] == 'multipolygon':\n",
    "                    # Multipolygons are a special case for relations\n",
    "                    # so they have thier own solver\n",
    "                    geometry = self._solve_relation_multipolygon(geometry)\n",
    "                else:\n",
    "                    geometry = self._solve_relation(geometry) \n",
    "            \n",
    "            # we need to make sure it is a an existing features\n",
    "            if f_type:\n",
    "                # if the geometry wasnt before solved we put the solved form back into the dataframe\n",
    "                # putting geometry into a list is a hack that gets around the ValueError: setting an array element with a sequence.\n",
    "                # see https://stackoverflow.com/questions/26483254/python-pandas-insert-list-into-a-cell\n",
    "                self.feature_df.loc[(self.feature_df['type'] == f_type) & (self.feature_df['id']==osmid), 'geometry'] = [geometry]\n",
    "\n",
    "        return geometry\n",
    "    \n",
    "    def _parse_osm_json(self,):\n",
    "        self.feature_list = []\n",
    "    \n",
    "        for element in self.osm_json['elements']:\n",
    "\n",
    "            if element['type'] == 'node':\n",
    "\n",
    "                if self.cache_nodes:\n",
    "                    # since nodes are the basis of all the things and not reliant on other features\n",
    "                    # we solve them when the dataframe gets created\n",
    "                    self.feature = [element['type'],element['id'],self._solve_node((element['lon'],element['lat'])),]\n",
    "                else:\n",
    "                    self.feature = [element['type'],element['id'],(element['lon'],element['lat']),]\n",
    "\n",
    "            elif element['type'] == 'way':\n",
    "                self.feature = [element['type'],element['id'],element['nodes'],]\n",
    "\n",
    "            elif element['type'] == 'relation':\n",
    "                self.feature = [element['type'],element['id'],element['members'],]\n",
    "\n",
    "            #not all elements have tags\n",
    "            try:\n",
    "                self.feature.append(element['tags'])                        \n",
    "            except:\n",
    "                self.feature.append(None) \n",
    "\n",
    "            self.feature_list.append(self.feature)\n",
    "\n",
    "        self.feature_df = pd.DataFrame(self.feature_list, columns=['type','id','geometry','tags'])\n",
    "        # because of the type of Overpass QL querry  \n",
    "        # see: https://help.openstreetmap.org/questions/78620/duplicate-features-retrieved-with-overpass-ql\n",
    "        # some features are duplicated in the dataframe so here we merge them and combine the tags of them\n",
    "        self.feature_df = self.feature_df.groupby(['type','id']).aggregate(self._agg_tags).reset_index()\n",
    "    \n",
    "    def _agg_tags(self,x):\n",
    "        # function aggregates multiple tags into one tags dictonary\n",
    "        # for all other columns (that are not part of the groupby)\n",
    "        # the first value is returned\n",
    "        # this follows the apriori assumption all other values are the same anyway\n",
    "\n",
    "        r_value = None\n",
    "        if x.name == 'tags':\n",
    "            _new_dict = {}\n",
    "            for element in x:\n",
    "                if type(element) == dict:\n",
    "                    _new_dict = {**_new_dict, **element}\n",
    "\n",
    "            if _new_dict:\n",
    "                r_value = _new_dict\n",
    "        \n",
    "        else:\n",
    "            r_value = x.iloc[0]\n",
    "    \n",
    "        return r_value    \n",
    "    \n",
    "    def _solve_node(self,lon_lat):\n",
    "        \n",
    "        return {'point':Point(lon_lat)}\n",
    "    \n",
    "    def _solve_way(self, node_list):\n",
    "        \n",
    "        point_geometries = [self.generate_geometry('node',node_id)['point'] for node_id in node_list]\n",
    "        \n",
    "        # its faster to filter None later rather than in the comprehension above\n",
    "        # otherwise I would querry the dataframe twice for one node    \n",
    "        point_geometries = [geom for geom in point_geometries if geom]\n",
    "        \n",
    "        # its a polygon if first and last element are the same\n",
    "        if node_list[0] == node_list[-1]:\n",
    "            temp_poly = Polygon(point_geometries)\n",
    "\n",
    "            # simple fix for invalid polygons\n",
    "            if not temp_poly.is_valid:\n",
    "                temp_poly = temp_poly.buffer(0)\n",
    "            \n",
    "            geom = {'polygon':temp_poly} \n",
    "        \n",
    "        else:\n",
    "            geom = {'line':LineString(point_geometries)}\n",
    "            \n",
    "        return geom\n",
    "    \n",
    "    def _solve_relation(self, member_list):\n",
    "        geom = {'multipoint':[],\n",
    "                'multiline':[],\n",
    "                'multipolygon':[]}\n",
    "        \n",
    "        for member in member_list:\n",
    "            member_geom = self.generate_geometry(member['type'],member['ref'])\n",
    "            \n",
    "            if not member_geom:\n",
    "                # if no geometrie for this member can be found we skip it\n",
    "                continue\n",
    "            \n",
    "            # since a member can also be a relation it can have multiple \n",
    "            # geometry types\n",
    "            for geom_type in member_geom:\n",
    "                if geom_type == 'point':\n",
    "                    geom['multipoint'].append(member_geom[geom_type])\n",
    "                if geom_type == 'multipoint':\n",
    "                    # multi features need to split to be later be put togehter again\n",
    "                    [geom['multipoint'].append(point) for point in list(member_geom[geom_type])]      \n",
    "                \n",
    "                if geom_type == 'line':\n",
    "                    geom['multiline'].append(member_geom[geom_type])\n",
    "                if geom_type == 'multiline':\n",
    "                    # multi features need to split to be later be put togehter again\n",
    "                    [geom['multiline'].append(point) for point in list(member_geom[geom_type])]    \n",
    "                \n",
    "                if geom_type == 'polygon':\n",
    "                    geom['multipolygon'].append(member_geom[geom_type])\n",
    "                if geom_type == 'multipolygon':\n",
    "                    # multi features need to split to be later be put togehter again\n",
    "                    [geom['multipolygon'].append(point) for point in list(member_geom[geom_type])] \n",
    "                    \n",
    "        geom_transform_func = {'multipoint':MultiPoint,\n",
    "                               'multiline':MultiLineString,\n",
    "                               'multipolygon':MultiPolygon,}\n",
    "        keys_to_delete = []\n",
    "        for geom_type in geom:\n",
    "            if geom[geom_type]:\n",
    "                geom[geom_type] = geom_transform_func[geom_type](geom[geom_type])\n",
    "            else:\n",
    "                keys_to_delete.append(geom_type)\n",
    "        \n",
    "        for key in keys_to_delete:\n",
    "            del geom[key]\n",
    "        \n",
    "        return geom\n",
    "   \n",
    "    def _solve_relation_multipolygon(self, member_list):\n",
    "        # osm has special multipolygon rules\n",
    "        # all the things that have an inner and an outer border are\n",
    "        # multipolygons represented as relations\n",
    "        # https://wiki.openstreetmap.org/wiki/Relation:multipolygon\n",
    "        # this function strictly folows the documentation\n",
    "        # i.e. it ignores points, other relations and incorrectly tagged ways\n",
    "        \n",
    "        # since not self-closed ways can be part of an multipolygon in osm\n",
    "        # but shapely does not like that we are also closing all polygons\n",
    "        member_dict = {'inner':[],'outer':[]}\n",
    "        \n",
    "        for member in member_list:\n",
    "            member_dict[member['role']].append(member['ref'])\n",
    "            \n",
    "        unclosed_ways = []\n",
    "        member_geom_dict = {'inner':[],'outer':[]}\n",
    "        # find and merge inner and outer unclosed ways\n",
    "        \n",
    "        for key in member_geom_dict:\n",
    "            for way_id in member_dict[key]:\n",
    "                # this gets us the list of node ids a way consinsts of\n",
    "                way_geom = self.generate_geometry('way',way_id)                \n",
    "                # now we sort into lines and polygons\n",
    "                if way_geom:\n",
    "                    try:\n",
    "                        member_geom_dict[key].append(way_geom['polygon'])\n",
    "                    except:\n",
    "                        # lines need to later be closed to form polygons full\n",
    "                        unclosed_ways.append(way_geom['line'])\n",
    "\n",
    "\n",
    "            if unclosed_ways:\n",
    "                # if unclosed ways exist try to merge them\n",
    "                member_geom_dict[key] += self._close_ways(unclosed_ways)\n",
    "\n",
    "            # now we make polygons out of all the ways\n",
    "            # complex list comprehesion ahead!\n",
    "            # we itterate once over all node list and the indivdualy over all \n",
    "            # node_ids to get the geometry for each\n",
    "\n",
    "            \n",
    "        # now lastly we have to solve which polygon is the inner to which outer polygon\n",
    "        multi_poly = self._solve_inner_outer(member_geom_dict)\n",
    "        \n",
    "        return {'multipolygon':multi_poly}\n",
    "    \n",
    "    def _close_ways(self,unclosed_ways):\n",
    "        closed_ways = []\n",
    "\n",
    "        while unclosed_ways:\n",
    "            way = unclosed_ways.pop()\n",
    "\n",
    "            # we pop up a way an try to merge it with any other of the ways\n",
    "            for match_way in unclosed_ways:\n",
    "                if way.coords[-1] == match_way.coords[0]:\n",
    "                    # if they are a match we merge them and \n",
    "                    # remove the copy of the matched way\n",
    "                    way = shapely.ops.linemerge(MultiLineString([way, match_way]))\n",
    "                    \n",
    "                    unclosed_ways.remove(match_way)\n",
    "                    break\n",
    "            \n",
    "            # if the way now is closed it goes into the closed way list\n",
    "            if way.coords[-1] == way.coords[0]:\n",
    "                closed_ways.append(Polygon(way))\n",
    "\n",
    "            # if not back into the pool of unclosed ways\n",
    "            else:\n",
    "                unclosed_ways.insert(0,way)\n",
    "\n",
    "            # if something goes wrong and only one way is left in here\n",
    "            # we break the loop \n",
    "            # this should not happen but osm data is wobbly\n",
    "            if len(unclosed_ways) == 1:\n",
    "                break\n",
    "\n",
    "        return closed_ways\n",
    "    \n",
    "    def _solve_inner_outer(self,geom_dict):\n",
    "        \n",
    "        solved_polys = {}\n",
    "        multi_list = []\n",
    "        # first we calculate the are for each of the outer polygons\n",
    "        # then sort them by size smalles first\n",
    "        # the idea is that an inner ring the innering to \n",
    "        # the smallest possible outer polygon is that it is containt within\n",
    "        outer_list = [(i,feature,feature.area) for i, feature in enumerate(geom_dict['outer'])]\n",
    "        outer_list.sort(key=lambda tup: tup[2])\n",
    "        \n",
    "        for i,feature,area in outer_list:\n",
    "            solved_polys[i] = {}\n",
    "            solved_polys[i]['outer'] = feature\n",
    "            solved_polys[i]['inner'] = []\n",
    "        \n",
    "        # here we itterate over all inner features and match them with an outer feature\n",
    "        for inner_feature in geom_dict['inner']:\n",
    "            for i,outer_feature,area in outer_list:\n",
    "                if outer_feature.contains(inner_feature):\n",
    "                    solved_polys[i]['inner'].append(inner_feature)\n",
    "             \n",
    "        # lastly we make shapely single polygons out of all of them \n",
    "        for i in solved_polys:\n",
    "            multi_list.append(Polygon(solved_polys[i]['outer'].exterior.coords,\n",
    "                                      [inner_feature.exterior.coords for inner_feature in solved_polys[i]['inner']]))\n",
    "\n",
    "        return MultiPolygon(multi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "innocent-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True\n",
    "if debug:\n",
    "    # Berlin polygon\n",
    "    q_poly = Polygon([(16.270485370522998, 48.24588384315554),\n",
    "                     (16.275485370522997, 48.24588384315554),\n",
    "                     (16.275485370522997, 48.25088384315554),\n",
    "                     (16.270485370522998, 48.25088384315554),\n",
    "                     (16.270485370522998, 48.24588384315554)])\n",
    "\n",
    "    # TU Wien polygon\n",
    "    #q_poly = Polygon([(48.20063653233946,16.36896371841431),(48.19960677385028,16.373598575592045),(48.19771882952509,16.371034383773807),(48.19816221664037,16.36772990226746)])\n",
    "    \n",
    "    osm_json = json_from_osm(q_poly)\n",
    "    \n",
    "    \n",
    "    test =  disect_osm(osm_json)\n",
    "#     osmid = test.feature_df[test.feature_df['type']=='relation'].sample().iloc[0]['id']\n",
    "#     test_multi = test.generate_geometry('relation',osmid)\n",
    "#     test_multi['multipolygon']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "democratic-winner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>node</td>\n",
       "      <td>380107</td>\n",
       "      <td>{'point': POINT (16.264169 48.2011516)}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>node</td>\n",
       "      <td>380111</td>\n",
       "      <td>{'point': POINT (16.2609 48.2018107)}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>node</td>\n",
       "      <td>380948</td>\n",
       "      <td>{'point': POINT (16.2452035 48.1376836)}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>node</td>\n",
       "      <td>381712</td>\n",
       "      <td>{'point': POINT (16.2690981 48.2376539)}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>node</td>\n",
       "      <td>381713</td>\n",
       "      <td>{'point': POINT (16.2696673 48.2384193)}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24024</th>\n",
       "      <td>way</td>\n",
       "      <td>901683912</td>\n",
       "      <td>[8376022346, 8376022347, 8376022348, 837602234...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24025</th>\n",
       "      <td>way</td>\n",
       "      <td>904555115</td>\n",
       "      <td>[8400615980, 8400615981, 8400615982, 840061598...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24026</th>\n",
       "      <td>way</td>\n",
       "      <td>906695434</td>\n",
       "      <td>[442683289, 2559690880, 78383526]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24027</th>\n",
       "      <td>way</td>\n",
       "      <td>907776192</td>\n",
       "      <td>[1893799762, 1893799760]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24028</th>\n",
       "      <td>way</td>\n",
       "      <td>907776193</td>\n",
       "      <td>[1893799768, 1893799762]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24029 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       type         id                                           geometry  \\\n",
       "0      node     380107            {'point': POINT (16.264169 48.2011516)}   \n",
       "1      node     380111              {'point': POINT (16.2609 48.2018107)}   \n",
       "2      node     380948           {'point': POINT (16.2452035 48.1376836)}   \n",
       "3      node     381712           {'point': POINT (16.2690981 48.2376539)}   \n",
       "4      node     381713           {'point': POINT (16.2696673 48.2384193)}   \n",
       "...     ...        ...                                                ...   \n",
       "24024   way  901683912  [8376022346, 8376022347, 8376022348, 837602234...   \n",
       "24025   way  904555115  [8400615980, 8400615981, 8400615982, 840061598...   \n",
       "24026   way  906695434                  [442683289, 2559690880, 78383526]   \n",
       "24027   way  907776192                           [1893799762, 1893799760]   \n",
       "24028   way  907776193                           [1893799768, 1893799762]   \n",
       "\n",
       "       tags  \n",
       "0      None  \n",
       "1      None  \n",
       "2      None  \n",
       "3      None  \n",
       "4      None  \n",
       "...     ...  \n",
       "24024  None  \n",
       "24025  None  \n",
       "24026  None  \n",
       "24027  None  \n",
       "24028  None  \n",
       "\n",
       "[24029 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "protecting-auckland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865fcaabb4b04e07a528165a22784bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb779276a194e44a739320a77efa81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[48.19911188084065, 16.370350493313698], controls=(ZoomControl(options=['position', 'zoom_in_text',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipyleaflet\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles, GeoJSON, WKTLayer\n",
    "from ipywidgets import Label\n",
    "\n",
    "# osmid = test.feature_df[test.feature_df['type']=='relation'].sample().iloc[0]['id']\n",
    "# test_multi = test.generate_geometry('relation',osmid)\n",
    "\n",
    "m = Map(\n",
    "    basemap=basemaps.CartoDB.Positron,\n",
    "    # for some reason lat lon are switch for centering the map\n",
    "    center=(q_poly.centroid.coords[0]),\n",
    "    zoom=14\n",
    ")\n",
    "\n",
    "wlayer = WKTLayer(\n",
    "    wkt_string=test_multi['multipolygon'].wkt,\n",
    "    #hover_style={\"fillColor\": \"red\"},\n",
    "    fill_color=\"red\",\n",
    "    color=\"red\",\n",
    ")\n",
    "\n",
    "wlayer2 = WKTLayer(\n",
    "    wkt_string=Polygon([(cord[1],cord[0]) for cord in q_poly.exterior.coords]).wkt,\n",
    "    #hover_style={\"fillColor\": \"red\"},\n",
    "\n",
    ")\n",
    "\n",
    "label = Label()\n",
    "display(label)\n",
    "\n",
    "\n",
    "\n",
    "def handle_interaction(**kwargs):\n",
    "    cords = '[]'\n",
    "    if kwargs.get('type') == 'click':\n",
    "        cords = f'{cords[:-1]}({kwargs.get(\"coordinates\")[0]},{kwargs.get(\"coordinates\")[1]})]'\n",
    "        label.value = cords\n",
    "\n",
    "m.on_interaction(handle_interaction)\n",
    "\n",
    "\n",
    "m.add_layer(wlayer)\n",
    "m.add_layer(wlayer2)\n",
    "\n",
    "# geo_json = GeoJSON(\n",
    "#     data=geojson_from_osm(poly,key='amenity',value='university'),\n",
    "#     color=\"red\",\n",
    "#     fill_color=\"red\"\n",
    "# )\n",
    "\n",
    "# m.add_layer(geo_json)\n",
    "\n",
    "\n",
    "# m"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
