{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "robust-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from shapely.geometry import Polygon, LineString, Point, MultiPolygon, MultiLineString, MultiPoint\n",
    "import shapely\n",
    "import osm2geojson\n",
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "worthy-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "overpass_url = \"http://overpass-api.de/api/interpreter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "widespread-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_querry_poly(poly):\n",
    "    # this function takes a shapely polygon and makes\n",
    "    # an overpass filter polygon out of it\n",
    "    # for the querry we will only support simple polygon\n",
    "    # - no multipolygons and \n",
    "    # - no inner rings\n",
    "    # because overpass does not support it\n",
    "    # https://wiki.openstreetmap.org/wiki/Overpass_API/Overpass_QL#By_polygon_.28poly.29\n",
    "    \n",
    "    #test if polygon conforms\n",
    "    assert isinstance(poly, shapely.geometry.polygon.Polygon), f'polygon is of {type(poly)} only shapely.geometry.polygon.Polygon is supported'\n",
    "    assert not list(poly.interiors), 'polygon has inner rings this is not supported by overpass filters' \n",
    "    \n",
    "    #simplyfy polygon if down to 101 cordinate pairs complex\n",
    "    while len(list(poly.exterior.coords)) >= 101:\n",
    "        # 0.1 is quite aggressive maybe 0.01 also works\n",
    "        poly = poly.simplify(0.1, preserve_topology=True)\n",
    "    \n",
    "    # extracts the exterior coords and puts them into a string\n",
    "    poly_string = ' '.join([f'{lat:.6f} {lon:.6f}' for lat,lon in list(poly.exterior.coords)])\n",
    "    \n",
    "    return poly_string\n",
    "\n",
    "\n",
    "def json_from_osm(poly, mode='nwr', key=None, value=None, operand='='):\n",
    "    \n",
    "    kv_filter = ''\n",
    "    if key:\n",
    "        kv_filter = f'[\"{key}\"]'\n",
    "    if value:\n",
    "        assert key, \"you can't pass a value without a key\"\n",
    "        kv_filter = f'{kv_filter[:-1]}{operand}\"{value}\"]'\n",
    "\n",
    "    query = f'''\n",
    "            [out:json][timeout:25];\n",
    "            (\n",
    "              {mode}{kv_filter}(poly:\"{generate_querry_poly(poly)}\");\n",
    "            );\n",
    "            out body;\n",
    "            >;\n",
    "            out skel qt;\n",
    "            '''\n",
    "    \n",
    "    respones = requests.get(overpass_url, params={'data': query})\n",
    "    \n",
    "    assert respones.ok, respones.text\n",
    "    \n",
    "    \n",
    "    # i'm not sure how osm2geojson deals with relations that contain points/polygons and line features\n",
    "    # turns out it doesn't\n",
    "    return respones.json()\n",
    "\n",
    "\n",
    "class disect_osm:\n",
    "    # when parsing osm data there exists a hugh issue with relations \n",
    "    # because they can contain multiple differnt kinds of geometries \n",
    "    # like polygons, lines, and points in the same thing they can even contain other\n",
    "    # relations that then again contain different types of geometries\n",
    "    # most osm parsers fail here\n",
    "    # so my idea is to split every relation into its most basic components\n",
    "    # so we get all features of relation a grouped by geometries type togehter \n",
    "    # with all the tags of realtion the relation\n",
    "    # for this i need to drill done every relation until I hit the the basic geometries\n",
    "    # points lines polygons and special case multiploygon\n",
    "    \n",
    "    def __init__(self, osm_json):\n",
    "        self.osm_json = osm_json\n",
    "        self._parse_osm_json()\n",
    "    \n",
    "    def generate_geometry(self, f_type, osmid):\n",
    "        # osmid within a feautre type are unique\n",
    "        # but its possible that there is a node relation and way with id 467\n",
    "\n",
    "        # select the feature in question from the df\n",
    "        self.feature = self.feature_df[(self.feature_df['type']==f_type) & (self.feature_df['id']==osmid)].iloc[0]\n",
    "        if f_type == 'node':\n",
    "            self.geometry = {'point':self.feature['geometry']}\n",
    "        \n",
    "        if f_type == 'way':\n",
    "            self.geometry = self._solve_ways(self.feature['geometry'])\n",
    "        \n",
    "        if f_type == 'relation':\n",
    "            if self.feature['tags']['type'] == 'multipolygon':\n",
    "                self.geometry = self._solve_relations_multipolygon(self.feature['geometry'])\n",
    "            else:\n",
    "                self.geometry = self._solve_relations(self.feature['geometry'])\n",
    " \n",
    "        \n",
    "        return self.geometry \n",
    "    \n",
    "    def _parse_osm_json(self,):\n",
    "        self.feature_list = []\n",
    "    \n",
    "        for element in self.osm_json['elements']:\n",
    "\n",
    "            if element['type'] == 'node':\n",
    "                self.feature = [element['type'],element['id'],Point(element['lon'],element['lat']),]\n",
    "\n",
    "            elif element['type'] == 'way':\n",
    "                self.feature = [element['type'],element['id'],element['nodes'],]\n",
    "\n",
    "            elif element['type'] == 'relation':\n",
    "                self.feature = [element['type'],element['id'],element['members'],]\n",
    "\n",
    "            #not all elements have tags\n",
    "            try:\n",
    "                self.feature.append(element['tags'])                        \n",
    "            except:\n",
    "                self.feature.append(None) \n",
    "\n",
    "            self.feature_list.append(self.feature)\n",
    "\n",
    "        self.feature_df = pd.DataFrame(self.feature_list,columns=['type','id','geometry','tags'])\n",
    "    \n",
    "    def _solve_ways(self, node_list):\n",
    "        \n",
    "        point_geometries = [self.generate_geometry('node',node_id)['point'] for node_id in node_list]\n",
    "        \n",
    "        # its a polygon if first and last element are the same\n",
    "        if node_list[0] == node_list[-1]:\n",
    "            temp_poly = Polygon(point_geometries)\n",
    "\n",
    "            # simple fix for invalid polygons\n",
    "            if not temp_poly.is_valid:\n",
    "                temp_poly = temp_poly.buffer(0)\n",
    "            \n",
    "            geom = {'polygon':temp_poly} \n",
    "        \n",
    "        else:\n",
    "            geom = {'line':LineString(point_geometries)}\n",
    "            \n",
    "        return geom\n",
    "    \n",
    "    def _solve_relations(self, member_list):\n",
    "        geom = {'multipoint':[],\n",
    "                'mulitline':[],\n",
    "                'mulitpolygon':[]}\n",
    "        \n",
    "        for member in member_list:\n",
    "            member_geom = self.generate_geometry(member['type'],member['ref'])\n",
    "            \n",
    "            for geom_type in member_geom:\n",
    "                if geom_type == 'point':\n",
    "                    geom['multipoint'].append(member_geom[geom_type])\n",
    "                if geom_type == 'multipoint':\n",
    "                    # multi features need to split to be later be put togehter again\n",
    "                    [geom['multipoint'].append(point) for point in list(member_geom[geom_type])]      \n",
    "                \n",
    "                if geom_type == 'line':\n",
    "                    geom['mulitline'].append(member_geom[geom_type])\n",
    "                if geom_type == 'mulitline':\n",
    "                    # multi features need to split to be later be put togehter again\n",
    "                    [geom['mulitline'].append(point) for point in list(member_geom[geom_type])]    \n",
    "                \n",
    "                if geom_type == 'polygon':\n",
    "                    geom['mulitpolygon'].append(member_geom[geom_type])\n",
    "                if geom_type == 'mulitpolygon':\n",
    "                    # multi features need to split to be later be put togehter again\n",
    "                    [geom['mulitpolygon'].append(point) for point in list(member_geom[geom_type])] \n",
    "                    \n",
    "        geom_transform_func = {'multipoint':MultiPoint,\n",
    "                               'mulitline':MultiLineString,\n",
    "                               'mulitpolygon':MultiPolygon,}\n",
    "        keys_to_delete = []\n",
    "        for geom_type in geom:\n",
    "            if geom[geom_type]:\n",
    "                geom[geom_type] = geom_transform_func[geom_type](geom[geom_type])\n",
    "            else:\n",
    "                keys_to_delete.append(geom_type)\n",
    "        \n",
    "        for key in keys_to_delete:\n",
    "            del geom[key]\n",
    "        \n",
    "        return geom\n",
    "   \n",
    "    def _solve_relations_multipolygon(self, member_list):\n",
    "        # osm has special mulitpolygon rules\n",
    "        # all the things that have an inner and an outer border are\n",
    "        # multipolygons represented as relations\n",
    "        # https://wiki.openstreetmap.org/wiki/Relation:multipolygon\n",
    "        # this function strictly folows the documentation\n",
    "        # i.e. it ignores points, other relations and incorrectly tagged ways\n",
    "        \n",
    "        # since not self-closed ways can be part of an multipolygon in osm\n",
    "        # but shapely does not like that we are also closing all polygons\n",
    "        member_dict = {'inner':[],'outer':[]}\n",
    "        \n",
    "        for member in member_list:\n",
    "            member_dict[member['role']].append(member['ref'])\n",
    "            \n",
    "        unclosed_ways = []\n",
    "        member_node_dict = {'inner':[],'outer':[]}\n",
    "        member_geom_dict = {'inner':[],'outer':[]}\n",
    "        # find and merge inner and outer unclosed ways\n",
    "        \n",
    "        for key in member_node_dict:\n",
    "            for way_id in member_dict[key]:\n",
    "                # this gets us the list of node ids a way consinsts of \n",
    "                way_nodes = self.feature_df[(self.feature_df['type']=='way') & (self.feature_df['id']==way_id)].iloc[0]['geometry']\n",
    "                \n",
    "                if not way_nodes[0] == way_nodes[-1]:\n",
    "                    unclosed_ways.append(way_nodes)\n",
    "                else:\n",
    "                    member_node_dict[key].append(way_nodes)\n",
    "\n",
    "                if unclosed_ways:\n",
    "                    # if unclosed ways exist try to merge them\n",
    "                    member_node_dict[key] += self._close_ways(unclosed_ways)\n",
    "\n",
    "            # now we make polygons out of all the ways\n",
    "            # complex list comprehesion ahead!\n",
    "            # we itterate once over all node list and the indivdualy over all \n",
    "            # node_ids to get the geometry for each\n",
    "            for node_list in member_node_dict[key]:\n",
    "                _tmp_list = []\n",
    "                for node_id in node_list:\n",
    "                    _tmp_list.append(self.generate_geometry('node',node_id)['point'])\n",
    "                \n",
    "                member_geom_dict[key].append(Polygon(_tmp_list))\n",
    "            \n",
    "        # now lastly we have to solve which polygon is the inner to which outer polygon\n",
    "        multi_poly = self._solve_inner_outer(member_geom_dict)\n",
    "        \n",
    "        return {'mulitpolygon':multi_poly}\n",
    "    \n",
    "    def _close_ways(self,unclosed_ways):\n",
    "        closed_ways = []\n",
    "\n",
    "        while unclosed_ways:\n",
    "            way = unclosed_ways.pop()\n",
    "\n",
    "            # we pop up a way an try to merge it with any other of the ways\n",
    "            for match_way in unclosed_ways:\n",
    "                if way[-1] == match_way[0]:\n",
    "                    # if they are a match we merge them and \n",
    "                    # remove the copy of the matched way\n",
    "                    way = way[:-1] + match_way\n",
    "                    unclosed_ways.remove(match_way)\n",
    "                    break\n",
    "            # if the way now is closed it goes into the closed way list\n",
    "            if way[0] == way[-1]:\n",
    "                closed_ways.append(way)\n",
    "\n",
    "            # if not back into the pool of unclosed ways\n",
    "            else:\n",
    "                unclosed_ways.insert(0,way)\n",
    "\n",
    "            # if something goes wrong and only one way is left in here\n",
    "            # we break the loop \n",
    "            # this should not happen but osm data is wobbly\n",
    "            if len(unclosed_ways) == 1:\n",
    "                break\n",
    "\n",
    "        return closed_ways\n",
    "    \n",
    "    def _solve_inner_outer(self,geom_dict):\n",
    "        \n",
    "        solved_polys = {}\n",
    "        multi_list = []\n",
    "        # first we calculate the are for each of the outer polygons\n",
    "        # then sort them by size smalles first\n",
    "        # the idea is that an inner ring the innering to \n",
    "        # the smallest possible outer polygon is that it is containt within\n",
    "        outer_list = [(i,feature,feature.area) for i, feature in enumerate(geom_dict['outer'])]\n",
    "        outer_list.sort(key=lambda tup: tup[1])\n",
    "        \n",
    "        for i,feature,area in outer_list:\n",
    "            solved_polys[i] = {}\n",
    "            solved_polys[i]['outer'] = feature\n",
    "            solved_polys[i]['inner'] = []\n",
    "        \n",
    "        # here we itterate over all inner features and match them with an outer feature\n",
    "        for inner_feature in geom_dict['inner']:\n",
    "            for i,outer_feature,area in outer_list:\n",
    "                if outer_feature.contains(inner_feature):\n",
    "                    solved_polys[i]['inner'].append(inner_feature)\n",
    "\n",
    "                    \n",
    "        # lastly we make shapely single polygons out of all of them \n",
    "        for i in solved_polys:\n",
    "            multi_list.append(Polygon(solved_polys[i]['outer'].exterior.coords,\n",
    "                                      [inner_feature.exterior.coords for inner_feature in solved_polys[i]['inner']]))\n",
    "\n",
    "        return MultiPolygon(multi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "accurate-niagara",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multipoint': <shapely.geometry.multipoint.MultiPoint at 0x7f64091a84c0>,\n",
       " 'mulitline': <shapely.geometry.multilinestring.MultiLineString at 0x7f6409f21280>,\n",
       " 'mulitpolygon': <shapely.geometry.multipolygon.MultiPolygon at 0x7f64091a87f0>}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =  disect_osm(osm_json)\n",
    "test_multi = test.generate_geometry('relation',2257692)\n",
    "test_multi\n",
    "#df[(df['type']=='way') & (df['id']==23045210)].iloc[0]['geometry']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "invalid-relative",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "        {\n",
    "            \"type\": \"relation\",\n",
    "            \"id\": 32590,\n",
    "            \"members\": [\n",
    "                {\n",
    "                    \"type\": \"way\",\n",
    "                    \"ref\": 401042452,\n",
    "                    \"role\": \"outer\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"way\",\n",
    "                    \"ref\": 26763294,\n",
    "                    \"role\": \"inner\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"way\",\n",
    "                    \"ref\": 26763298,\n",
    "                    \"role\": \"inner\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"way\",\n",
    "                    \"ref\": 26763311,\n",
    "                    \"role\": \"inner\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"way\",\n",
    "                    \"ref\": 26763333,\n",
    "                    \"role\": \"inner\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"way\",\n",
    "                    \"ref\": 26763337,\n",
    "                    \"role\": \"inner\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"way\",\n",
    "                    \"ref\": 26763349,\n",
    "                    \"role\": \"inner\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"way\",\n",
    "                    \"ref\": 26763359,\n",
    "                    \"role\": \"inner\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"way\",\n",
    "                    \"ref\": 26763383,\n",
    "                    \"role\": \"inner\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"way\",\n",
    "                    \"ref\": 26763404,\n",
    "                    \"role\": \"inner\"\n",
    "                }\n",
    "            ],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "derived-change",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9bef8319ce24756b6ceecaa704a010e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[52.4515813, 13.289878], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipyleaflet\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles,GeoJSON, WKTLayer\n",
    "\n",
    "m = Map(\n",
    "    basemap=basemaps.CartoDB.Positron,\n",
    "    center=(52.4515813, 13.289878),\n",
    "    zoom=14\n",
    ")\n",
    "\n",
    "# polygon = ipyleaflet.Polygon(\n",
    "#     locations= [\n",
    "#         list(poly.exterior.coords)\n",
    "#     ],\n",
    "#     color=\"green\",\n",
    "#     fill_color=\"green\"\n",
    "# )\n",
    "# m.add_layer(polygon)\n",
    "\n",
    "wlayer = WKTLayer(\n",
    "    wkt_string=test_multi['mulitline'].wkt,\n",
    "    #hover_style={\"fillColor\": \"red\"},\n",
    "    fill_color=\"red\",\n",
    "    color=\"red\",\n",
    ")\n",
    "m.add_layer(wlayer)\n",
    "\n",
    "# geo_json = GeoJSON(\n",
    "#     data=geojson_from_osm(poly,key='amenity',value='university'),\n",
    "#     color=\"red\",\n",
    "#     fill_color=\"red\"\n",
    "# )\n",
    "\n",
    "# m.add_layer(geo_json)\n",
    "\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-johnston",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
