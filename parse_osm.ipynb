{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "herbal-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from shapely.geometry import Polygon, LineString, Point, MultiPolygon, MultiLineString, MultiPoint\n",
    "import shapely\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "whole-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO's:\n",
    "#  - first\n",
    "# in the discet osm class every geometrie is build from the nodes up when querried\n",
    "# this is resource intensive espacily because geometries in osm tend to be reused\n",
    "# so in future when a geometrie was build it will be saved back in build form\n",
    "# to the dataframe this will be more memory intensive but i think it is worth the trade of\n",
    "# - second\n",
    "# I want to make the disection multithread able espacialy in context of the first\n",
    "# todo this would I think immensily speed up the proccesing of the osm data\n",
    "# the dataframe could be the common data storage for all threads\n",
    "# and if one of the threads has solved a geomtry and stored it back in the dataframe\n",
    "# the other threads can retrieve it and don't even need to solve it themselfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "married-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "overpass_url = \"http://overpass-api.de/api/interpreter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fresh-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_querry_poly(poly):\n",
    "    # this function takes a shapely polygon and makes\n",
    "    # an overpass filter polygon out of it\n",
    "    # for the querry we will only support simple polygon\n",
    "    # - no multipolygons and \n",
    "    # - no inner rings\n",
    "    # because overpass does not support it\n",
    "    # https://wiki.openstreetmap.org/wiki/Overpass_API/Overpass_QL#By_polygon_.28poly.29\n",
    "    \n",
    "    #test if polygon conforms\n",
    "    assert isinstance(poly, shapely.geometry.polygon.Polygon), f'polygon is of {type(poly)} only shapely.geometry.polygon.Polygon is supported'\n",
    "    assert not list(poly.interiors), 'polygon has inner rings this is not supported by overpass filters' \n",
    "    \n",
    "    #simplyfy polygon if down to 101 cordinate pairs complex\n",
    "    while len(list(poly.exterior.coords)) >= 101:\n",
    "        # 0.1 is quite aggressive maybe 0.01 also works\n",
    "        poly = poly.simplify(0.1, preserve_topology=True)\n",
    "    \n",
    "    # extracts the exterior coords and puts them into a string\n",
    "    poly_string = ' '.join([f'{lat:.6f} {lon:.6f}' for lat,lon in list(poly.exterior.coords)])\n",
    "    \n",
    "    return poly_string\n",
    "\n",
    "\n",
    "def json_from_osm(poly, mode='nwr', key=None, value=None, operand='='):\n",
    "    \n",
    "    kv_filter = ''\n",
    "    if key:\n",
    "        kv_filter = f'[\"{key}\"]'\n",
    "    if value:\n",
    "        assert key, \"you can't pass a value without a key\"\n",
    "        kv_filter = f'{kv_filter[:-1]}{operand}\"{value}\"]'\n",
    "\n",
    "    query = f'''\n",
    "            [out:json][timeout:25];\n",
    "            (\n",
    "              {mode}{kv_filter}(poly:\"{generate_querry_poly(poly)}\");\n",
    "            );\n",
    "            out body;\n",
    "            >;\n",
    "            out skel qt;\n",
    "            '''\n",
    "\n",
    "    respones = requests.get(overpass_url, params={'data': query})\n",
    "    \n",
    "    assert respones.ok, respones.text\n",
    "\n",
    "    return respones.json()\n",
    "\n",
    "\n",
    "class disect_osm:\n",
    "    # when parsing osm data there exists a hugh issue with relations \n",
    "    # because they can contain multiple differnt kinds of geometries \n",
    "    # like polygons, lines, and points in the same thing they can even contain other\n",
    "    # relations that then again contain different types of geometries\n",
    "    # most osm parsers fail here\n",
    "    # so my idea is to split every relation into its most basic components\n",
    "    # so we get all features of relation a grouped by geometries type togehter \n",
    "    # with all the tags of realtion the relation\n",
    "    # for this i need to drill done every relation until I hit the the basic geometries\n",
    "    # points lines polygons and special case multiploygon\n",
    "    \n",
    "    def __init__(self, osm_json, cache_nodes=True):\n",
    "        self.osm_json = osm_json\n",
    "        self.cache_nodes = cache_nodes\n",
    "        # these are all the geometrie types features can have, relations can have multiple of those\n",
    "        self.geometry_types = ['point','multipoint','line','multiline','polygon','multipolygon']\n",
    "        self._parse_osm_json()\n",
    "    \n",
    "    def generate_geometry(self, f_type, osmid):\n",
    "        # osmid within a feautre type are unique\n",
    "        # but its possible that there is a node relation and way with id 467\n",
    "        # select the feature in question from the df\n",
    "        try:\n",
    "            # recusion does some times fail when the feature refferenced wasn't retrieved from osm\n",
    "            feature = self.feature_df[(self.feature_df['type']==f_type) & (self.feature_df['id']==osmid)].iloc[0]\n",
    "            geometry = feature['geometry']\n",
    "        except:\n",
    "            f_type = None\n",
    "            geometry = None\n",
    "        \n",
    "        # test if the geometry is already pressent in solved form in the dataframe\n",
    "        # if not we solve it otherwise we return what was fetched\n",
    "        try:\n",
    "            # this is a bit hacky but what it accomplishes is to test if \n",
    "            # geometry is a dictonary and if so it contains on of the geometry keys\n",
    "            # in any other case this throws an exception\n",
    "            if not list(geometry.keys())[0] in self.geometry_types:\n",
    "                raise Exception\n",
    "        \n",
    "        except:\n",
    "            \n",
    "            if f_type == 'node':\n",
    "                geometry = self._solve_node(geometry)\n",
    "\n",
    "            if f_type == 'way':\n",
    "                geometry = self._solve_way(geometry)\n",
    "\n",
    "            if f_type == 'relation':\n",
    "                if feature['tags']['type'] == 'multipolygon':\n",
    "                    # Multipolygons are a special case for relations\n",
    "                    # so they have thier own solver\n",
    "                    geometry = self._solve_relation_multipolygon(geometry)\n",
    "                else:\n",
    "                    geometry = self._solve_relation(geometry) \n",
    "            \n",
    "            # we need to make sure it is a an existing features\n",
    "            if f_type:\n",
    "                # if the geometry wasnt before solved we put the solved form back into the dataframe\n",
    "                # putting geometry into a list is a hack that gets around the ValueError: setting an array element with a sequence.\n",
    "                # see https://stackoverflow.com/questions/26483254/python-pandas-insert-list-into-a-cell\n",
    "                self.feature_df.loc[(self.feature_df['type'] == f_type) & (self.feature_df['id']==osmid), 'geometry'] = [geometry]\n",
    "\n",
    "        return geometry\n",
    "    \n",
    "    def _parse_osm_json(self,):\n",
    "        self.feature_list = []\n",
    "    \n",
    "        for element in self.osm_json['elements']:\n",
    "\n",
    "            if element['type'] == 'node':\n",
    "\n",
    "                if self.cache_nodes:\n",
    "                    # since nodes are the basis of all the things and not reliant on other features\n",
    "                    # we solve them when the dataframe gets created\n",
    "                    self.feature = [element['type'],element['id'],self._solve_node((element['lon'],element['lat'])),]\n",
    "                else:\n",
    "                    self.feature = [element['type'],element['id'],(element['lon'],element['lat']),]\n",
    "\n",
    "            elif element['type'] == 'way':\n",
    "                self.feature = [element['type'],element['id'],element['nodes'],]\n",
    "\n",
    "            elif element['type'] == 'relation':\n",
    "                self.feature = [element['type'],element['id'],element['members'],]\n",
    "\n",
    "            #not all elements have tags\n",
    "            try:\n",
    "                self.feature.append(element['tags'])                        \n",
    "            except:\n",
    "                self.feature.append(None) \n",
    "\n",
    "            self.feature_list.append(self.feature)\n",
    "\n",
    "        self.feature_df = pd.DataFrame(self.feature_list, columns=['type','id','geometry','tags'])\n",
    "        # because of the type of Overpass QL querry  \n",
    "        # see: https://help.openstreetmap.org/questions/78620/duplicate-features-retrieved-with-overpass-ql\n",
    "        # some features are duplicated in the dataframe so here we merge them and combine the tags of them\n",
    "        self.feature_df = self.feature_df.groupby(['type','id']).aggregate(self._agg_tags).reset_index()\n",
    "    \n",
    "    def _agg_tags(self,x):\n",
    "        # function aggregates multiple tags into one tags dictonary\n",
    "        # for all other columns (that are not part of the groupby)\n",
    "        # the first value is returned\n",
    "        # this follows the apriori assumption all other values are the same anyway\n",
    "\n",
    "        r_value = None\n",
    "        if x.name == 'tags':\n",
    "            _new_dict = {}\n",
    "            for element in x:\n",
    "                if type(element) == dict:\n",
    "                    _new_dict = {**_new_dict, **element}\n",
    "\n",
    "            if _new_dict:\n",
    "                r_value = _new_dict\n",
    "        \n",
    "        else:\n",
    "            r_value = x.iloc[0]\n",
    "    \n",
    "        return r_value    \n",
    "    \n",
    "    def _solve_node(self,lon_lat):\n",
    "        \n",
    "        return {'point':Point(lon_lat)}\n",
    "    \n",
    "    def _solve_way(self, node_list):\n",
    "        \n",
    "        point_geometries = [self.generate_geometry('node',node_id)['point'] for node_id in node_list]\n",
    "        \n",
    "        # its faster to filter None later rather than in the comprehension above\n",
    "        # otherwise I would querry the dataframe twice for one node    \n",
    "        point_geometries = [geom for geom in point_geometries if geom]\n",
    "        \n",
    "        # its a polygon if first and last element are the same\n",
    "        if node_list[0] == node_list[-1]:\n",
    "            temp_poly = Polygon(point_geometries)\n",
    "\n",
    "            # simple fix for invalid polygons\n",
    "            if not temp_poly.is_valid:\n",
    "                temp_poly = temp_poly.buffer(0)\n",
    "            \n",
    "            geom = {'polygon':temp_poly} \n",
    "        \n",
    "        else:\n",
    "            geom = {'line':LineString(point_geometries)}\n",
    "            \n",
    "        return geom\n",
    "    \n",
    "    def _solve_relation(self, member_list):\n",
    "        geom = {'multipoint':[],\n",
    "                'multiline':[],\n",
    "                'multipolygon':[]}\n",
    "        \n",
    "        for member in member_list:\n",
    "            member_geom = self.generate_geometry(member['type'],member['ref'])\n",
    "            \n",
    "            if not member_geom:\n",
    "                # if no geometrie for this member can be found we skip it\n",
    "                continue\n",
    "            \n",
    "            # since a member can also be a relation it can have multiple \n",
    "            # geometry types\n",
    "            for geom_type in member_geom:\n",
    "                if geom_type == 'point':\n",
    "                    geom['multipoint'].append(member_geom[geom_type])\n",
    "                if geom_type == 'multipoint':\n",
    "                    # multi features need to split to be later be put togehter again\n",
    "                    [geom['multipoint'].append(point) for point in list(member_geom[geom_type])]      \n",
    "                \n",
    "                if geom_type == 'line':\n",
    "                    geom['multiline'].append(member_geom[geom_type])\n",
    "                if geom_type == 'multiline':\n",
    "                    # multi features need to split to be later be put togehter again\n",
    "                    [geom['multiline'].append(point) for point in list(member_geom[geom_type])]    \n",
    "                \n",
    "                if geom_type == 'polygon':\n",
    "                    geom['multipolygon'].append(member_geom[geom_type])\n",
    "                if geom_type == 'multipolygon':\n",
    "                    # multi features need to split to be later be put togehter again\n",
    "                    [geom['multipolygon'].append(point) for point in list(member_geom[geom_type])] \n",
    "                    \n",
    "        geom_transform_func = {'multipoint':MultiPoint,\n",
    "                               'multiline':MultiLineString,\n",
    "                               'multipolygon':MultiPolygon,}\n",
    "        keys_to_delete = []\n",
    "        for geom_type in geom:\n",
    "            if geom[geom_type]:\n",
    "                geom[geom_type] = geom_transform_func[geom_type](geom[geom_type])\n",
    "            else:\n",
    "                keys_to_delete.append(geom_type)\n",
    "        \n",
    "        for key in keys_to_delete:\n",
    "            del geom[key]\n",
    "        \n",
    "        return geom\n",
    "   \n",
    "    def _solve_relation_multipolygon(self, member_list):\n",
    "        # osm has special multipolygon rules\n",
    "        # all the things that have an inner and an outer border are\n",
    "        # multipolygons represented as relations\n",
    "        # https://wiki.openstreetmap.org/wiki/Relation:multipolygon\n",
    "        # this function strictly folows the documentation\n",
    "        # i.e. it ignores points, other relations and incorrectly tagged ways\n",
    "        \n",
    "        # since not self-closed ways can be part of an multipolygon in osm\n",
    "        # but shapely does not like that we are also closing all polygons\n",
    "        member_dict = {'inner':[],'outer':[]}\n",
    "        \n",
    "        for member in member_list:\n",
    "            member_dict[member['role']].append(member['ref'])\n",
    "            \n",
    "        unclosed_ways = []\n",
    "        member_geom_dict = {'inner':[],'outer':[]}\n",
    "        # find and merge inner and outer unclosed ways\n",
    "        \n",
    "        for key in member_geom_dict:\n",
    "            for way_id in member_dict[key]:\n",
    "                # this gets us the list of node ids a way consinsts of\n",
    "                way_geom = self.generate_geometry('way',way_id)\n",
    "                # way_nodes = self.feature_df[(self.feature_df['type']=='way') & (self.feature_df['id']==way_id)].iloc[0]['geometry']\n",
    "                \n",
    "                # now we sort into lines and polygons\n",
    "                if way_geom:\n",
    "                    try:\n",
    "                        member_geom_dict[key].append(way_geom['polygon'])\n",
    "                    except:\n",
    "                        # lines need to later be closed to form polygons full\n",
    "                        unclosed_ways.append(way_geom['line'])\n",
    "\n",
    "\n",
    "            if unclosed_ways:\n",
    "                # if unclosed ways exist try to merge them\n",
    "                member_geom_dict[key] += self._close_ways(unclosed_ways)\n",
    "\n",
    "            # now we make polygons out of all the ways\n",
    "            # complex list comprehesion ahead!\n",
    "            # we itterate once over all node list and the indivdualy over all \n",
    "            # node_ids to get the geometry for each\n",
    "\n",
    "            \n",
    "        # now lastly we have to solve which polygon is the inner to which outer polygon\n",
    "        multi_poly = self._solve_inner_outer(member_geom_dict)\n",
    "        \n",
    "        return {'multipolygon':multi_poly}\n",
    "    \n",
    "    def _close_ways(self,unclosed_ways):\n",
    "        closed_ways = []\n",
    "\n",
    "        while unclosed_ways:\n",
    "            way = unclosed_ways.pop()\n",
    "\n",
    "            # we pop up a way an try to merge it with any other of the ways\n",
    "            for match_way in unclosed_ways:\n",
    "                if way.coords[-1] == match_way.coords[0]:\n",
    "                    # if they are a match we merge them and \n",
    "                    # remove the copy of the matched way\n",
    "                    way = shapely.ops.linemerge(geometry.MultiLineString([way, match_way]))\n",
    "                    \n",
    "                    unclosed_ways.remove(match_way)\n",
    "                    break\n",
    "            \n",
    "            # if the way now is closed it goes into the closed way list\n",
    "            if way[0].coords[-1] == way.coords[0]:\n",
    "                closed_ways.append(Polygon(way))\n",
    "\n",
    "            # if not back into the pool of unclosed ways\n",
    "            else:\n",
    "                unclosed_ways.insert(0,way)\n",
    "\n",
    "            # if something goes wrong and only one way is left in here\n",
    "            # we break the loop \n",
    "            # this should not happen but osm data is wobbly\n",
    "            if len(unclosed_ways) == 1:\n",
    "                break\n",
    "\n",
    "        return closed_ways\n",
    "    \n",
    "    def _solve_inner_outer(self,geom_dict):\n",
    "        \n",
    "        solved_polys = {}\n",
    "        multi_list = []\n",
    "        # first we calculate the are for each of the outer polygons\n",
    "        # then sort them by size smalles first\n",
    "        # the idea is that an inner ring the innering to \n",
    "        # the smallest possible outer polygon is that it is containt within\n",
    "        outer_list = [(i,feature,feature.area) for i, feature in enumerate(geom_dict['outer'])]\n",
    "        outer_list.sort(key=lambda tup: tup[2])\n",
    "        \n",
    "        for i,feature,area in outer_list:\n",
    "            solved_polys[i] = {}\n",
    "            solved_polys[i]['outer'] = feature\n",
    "            solved_polys[i]['inner'] = []\n",
    "        \n",
    "        # here we itterate over all inner features and match them with an outer feature\n",
    "        for inner_feature in geom_dict['inner']:\n",
    "            for i,outer_feature,area in outer_list:\n",
    "                if outer_feature.contains(inner_feature):\n",
    "                    solved_polys[i]['inner'].append(inner_feature)\n",
    "\n",
    "                    \n",
    "        # lastly we make shapely single polygons out of all of them \n",
    "        for i in solved_polys:\n",
    "            multi_list.append(Polygon(solved_polys[i]['outer'].exterior.coords,\n",
    "                                      [inner_feature.exterior.coords for inner_feature in solved_polys[i]['inner']]))\n",
    "\n",
    "        return MultiPolygon(multi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "assured-advertising",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"13.294993408 52.453723308 0.0010311840000003514 0.0006375839999961386\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,104.90808419999999)\"><g><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"2.0623680000007026e-05\" opacity=\"0.6\" d=\"M 13.2956732,52.4538882 L 13.2959864,52.4540177 L 13.2958275,52.4541613 L 13.2955126,52.4540312 L 13.2951906,52.4543227 L 13.2950316,52.4542558 L 13.2955582,52.4537685 L 13.2955888,52.4537794 L 13.2956098,52.4537615 L 13.2957044,52.453802 L 13.2956867,52.4538192 L 13.2957311,52.4538377 L 13.2956732,52.4538882 z M 13.2956502,52.454032 L 13.2955589,52.4539962 L 13.2956308,52.4539268 L 13.2957249,52.4539638 L 13.2956502,52.454032 z\" /></g></g></svg>"
      ],
      "text/plain": [
       "<shapely.geometry.multipolygon.MultiPolygon at 0x7f02646c0d60>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug = True\n",
    "if debug:\n",
    "    # Berlin polygon\n",
    "    q_poly = Polygon([(52.450425727741,13.286182880402),(52.458323725344,13.286182880402),(52.458323725344,13.299744129181),(52.450425727741,13.299744129181)])\n",
    "    \n",
    "    # TU Wien polygon\n",
    "    #q_poly = Polygon([(48.20063653233946,16.36896371841431),(48.19960677385028,16.373598575592045),(48.19771882952509,16.371034383773807),(48.19816221664037,16.36772990226746)])\n",
    "    \n",
    "    osm_json = json_from_osm(q_poly)\n",
    "    \n",
    "    \n",
    "    test =  disect_osm(osm_json)\n",
    "    osmid = test.feature_df[test.feature_df['type']=='relation'].sample().iloc[0]['id']\n",
    "    test_multi = test.generate_geometry('relation',osmid)\n",
    "test_multi['multipolygon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "played-discrimination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multipoint': <shapely.geometry.multipoint.MultiPoint at 0x7f76c653e850>,\n",
       " 'multiline': <shapely.geometry.multilinestring.MultiLineString at 0x7f76ce0cc160>}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.generate_geometry('relation',6486683)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "lesser-jesus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33406 entries, 0 to 33405\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   type      33406 non-null  object\n",
      " 1   id        33406 non-null  int64 \n",
      " 2   geometry  33406 non-null  object\n",
      " 3   tags      6826 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 11.0 MB\n"
     ]
    }
   ],
   "source": [
    "test.feature_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "decent-preview",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48.19911188084065, 16.370350493313698)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_poly.centroid.coords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "prime-preservation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865fcaabb4b04e07a528165a22784bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb779276a194e44a739320a77efa81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[48.19911188084065, 16.370350493313698], controls=(ZoomControl(options=['position', 'zoom_in_text',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipyleaflet\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles, GeoJSON, WKTLayer\n",
    "from ipywidgets import Label\n",
    "\n",
    "# osmid = test.feature_df[test.feature_df['type']=='relation'].sample().iloc[0]['id']\n",
    "# test_multi = test.generate_geometry('relation',osmid)\n",
    "\n",
    "m = Map(\n",
    "    basemap=basemaps.CartoDB.Positron,\n",
    "    # for some reason lat lon are switch for centering the map\n",
    "    center=(q_poly.centroid.coords[0]),\n",
    "    zoom=14\n",
    ")\n",
    "\n",
    "wlayer = WKTLayer(\n",
    "    wkt_string=test_multi['multipolygon'].wkt,\n",
    "    #hover_style={\"fillColor\": \"red\"},\n",
    "    fill_color=\"red\",\n",
    "    color=\"red\",\n",
    ")\n",
    "\n",
    "wlayer2 = WKTLayer(\n",
    "    wkt_string=Polygon([(cord[1],cord[0]) for cord in q_poly.exterior.coords]).wkt,\n",
    "    #hover_style={\"fillColor\": \"red\"},\n",
    "\n",
    ")\n",
    "\n",
    "label = Label()\n",
    "display(label)\n",
    "\n",
    "\n",
    "\n",
    "def handle_interaction(**kwargs):\n",
    "    cords = '[]'\n",
    "    if kwargs.get('type') == 'click':\n",
    "        cords = f'{cords[:-1]}({kwargs.get(\"coordinates\")[0]},{kwargs.get(\"coordinates\")[1]})]'\n",
    "        label.value = cords\n",
    "\n",
    "m.on_interaction(handle_interaction)\n",
    "\n",
    "\n",
    "m.add_layer(wlayer)\n",
    "m.add_layer(wlayer2)\n",
    "\n",
    "# geo_json = GeoJSON(\n",
    "#     data=geojson_from_osm(poly,key='amenity',value='university'),\n",
    "#     color=\"red\",\n",
    "#     fill_color=\"red\"\n",
    "# )\n",
    "\n",
    "# m.add_layer(geo_json)\n",
    "\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "spoken-material",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22605 entries, 0 to 22604\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   type      22605 non-null  object\n",
      " 1   id        22605 non-null  int64 \n",
      " 2   geometry  22605 non-null  object\n",
      " 3   tags      2444 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 706.5+ KB\n"
     ]
    }
   ],
   "source": [
    "test.feature_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
