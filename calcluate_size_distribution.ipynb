{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "received-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The idea of this script is calculate size distrbutions of osm Features \n",
    "# of intresset is to calculate a distrbution for each key value pair that is \n",
    "# listed on the wikipages refrences in osm_groups.txt\n",
    "# for this we will randomly querry the whole OSM dataset to collect samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "enhanced-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gis.stackexchange.com/questions/127427/transforming-shapely-polygon-and-multipolygon-objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "arctic-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parse_osm\n",
    "from shapely.geometry import Polygon, LineString, Point, MultiPolygon, MultiLineString, MultiPoint\n",
    "import random\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pyproj\n",
    "import numpy as np\n",
    "import fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "retired-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_bb(size,constrain=None):\n",
    "    # size has to be in degrees since to BB for osm is in degrees\n",
    "    # constrain has to be a shapely (multi-)polygon and can be used to limit the area\n",
    "    \n",
    "    # if a constrain exist we shrink the possibility space donw to the bounds of it \n",
    "    if constrain:\n",
    "        minx, miny, maxx, maxy = constrain.bounds\n",
    "    else:\n",
    "        minx, miny, maxx, maxy = -180,-90,180,90\n",
    "    \n",
    "    # we generate first the lower left corner of the bounding box\n",
    "    if constrain:\n",
    "        # when an constrain exist we make shure the point is within it\n",
    "        ll_x,ll_y =-9999999,-9999999\n",
    "        while not constrain.contains(Point(ll_x, ll_y)):\n",
    "            ll_x,ll_y = random.uniform(minx, maxx),random.uniform(miny, maxy)\n",
    "    else:\n",
    "        ll_x,ll_y = random.uniform(minx, maxx),random.uniform(miny, maxy)\n",
    "        \n",
    "    \n",
    "     \n",
    "    return Polygon([(ll_x,ll_y),(ll_x+size,ll_y),(ll_x+size,ll_y+size),(ll_x,ll_y+size)])\n",
    "    \n",
    "    \n",
    "def generate_tag_list(df):\n",
    "    tag_list = []\n",
    "    for row in df.iterrows():\n",
    "        tag_list.append(f\"{row[1]['key']} {row[1]['value']}\")\n",
    "    \n",
    "    return tag_list\n",
    "\n",
    "\n",
    "def filter_tags(row):\n",
    "    # this function looks if key,value are present in the tag_list \n",
    "    # if so it returns true\n",
    "    r_value = False\n",
    "    if row['tags']:\n",
    "        for key in row['tags'].keys():\n",
    "            if f\"{key} {row['tags'][key]}\" in tag_list:\n",
    "                 r_value = True\n",
    "    return r_value\n",
    "\n",
    "\n",
    "def line_length(line):\n",
    "    \n",
    "    geod = pyproj.Geod(ellps='WGS84')\n",
    "    line_length = geod.geometry_length(line)\n",
    "\n",
    "    return abs(line_length)\n",
    "\n",
    "\n",
    "def poly_area(poly):\n",
    "\n",
    "    geod = pyproj.Geod(ellps='WGS84')\n",
    "    poly_area = geod.geometry_area_perimeter(poly)[0]\n",
    "    \n",
    "    return abs(poly_area)\n",
    "\n",
    "\n",
    "def calcualte_size_for_tags(row):\n",
    "    #print(row)\n",
    "    geometry, tags  = row['geometry'], row['tags']\n",
    "    sizes_dict = {}\n",
    "    for key in geometry.keys():\n",
    "        if 'line' in key:\n",
    "            sizes_dict['length'] = line_length(geometry[key])\n",
    "        elif 'poly' in key:\n",
    "            sizes_dict['area'] = poly_area(geometry[key])\n",
    "            \n",
    "    # we only keep tag key combinations that are part of tag_list     \n",
    "    key_val_list = [f'{key} {tags[key]}' for key in tags.keys() if f'{key} {tags[key]}' in tag_list]\n",
    "    \n",
    "    return_dict = {}\n",
    "    \n",
    "    # a geometry might have more than one relevant tag\n",
    "    # {'tag_key':{'length':,'area':},'tag_key2':{'length':,'area':}}\n",
    "    for key_val in key_val_list:\n",
    "        return_dict[key_val] = sizes_dict\n",
    "\n",
    "    return return_dict\n",
    "\n",
    "\n",
    "def agg_len_area(x):\n",
    "    length = [el for el in x['length'].tolist() if el]\n",
    "    area = [el for el in x['area'].tolist() if el]\n",
    "    \n",
    "    return pd.Series({'area':area,'length':length}, index=['area', 'length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "registered-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameters\n",
    "# this sets how many itterations we will go for \n",
    "n_iter = 10\n",
    "\n",
    "# we can define an area in which we ware looking for key value combinations\n",
    "# if this is not supplied the whole world will be querried\n",
    "# polygon can be arbitrarie (must be in degrees) but only the lower left corner of the random bounding box\n",
    "# is quaranteete to be within the polygon\n",
    "#q_poly = Polygon([(52.450425727741,13.286182880402),(52.458323725344,13.286182880402),(52.458323725344,13.299744129181),(52.450425727741,13.299744129181)])\n",
    "level_1_admin = gpd.read_file(\"../data/shapes/level_1_admin/ne_10m_admin_1_states_provinces.shp\")\n",
    "# in this case we select vienna as the polyon\n",
    "q_poly  = level_1_admin[level_1_admin['name']=='Wien']['geometry'].iloc[0]\n",
    "\n",
    "# here we define the size of our random bounding box in degrees\n",
    "# 0.001Â° =111 m\n",
    "bb_size = 0.005\n",
    "\n",
    "# now we load the predefined tags from pickle\n",
    "tag_df =  pd.read_pickle('./kv_df_just_eng.pickle')\n",
    "tag_list = generate_tag_list(tag_df)\n",
    "\n",
    "# we need the results_df to collect all the values\n",
    "results_df = pd.DataFrame(columns=['key','value','area','length']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "waiting-microwave",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a52da9fd083f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# and filter the querried polygons for a) if a tag from the tag_list is pressent and b) if they are not just a point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mselected_geom_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mosm_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosm_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mosm_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'node'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtype_id_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselected_geom_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# for the selected features we calculate the geometry:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'type'"
     ]
    }
   ],
   "source": [
    "for i in range(n_iter):\n",
    "    r_bb = random_bb(bb_size,q_poly)\n",
    "    # we use the generated polygon to querry osm for all features within the bounding box\n",
    "    osm_handle = parse_osm.disect_osm(parse_osm.json_from_osm(r_bb))\n",
    "\n",
    "    # and filter the querried polygons for a) if a tag from the tag_list is pressent and b) if they are not just a point \n",
    "    selected_geom_df = osm_handle.feature_df[(osm_handle.feature_df.apply(filter_tags, axis= 1)) & (osm_handle.feature_df['type'] != 'node')] \n",
    "    type_id_list = selected_geom_df[['type','id']].values.tolist()\n",
    "    # for the selected features we calculate the geometry:\n",
    "    [osm_handle.generate_geometry(f_type,osm_id) for f_type, osm_id in type_id_list]\n",
    "    # and reselect them\n",
    "    selected_geom_df = osm_handle.feature_df[(osm_handle.feature_df.apply(filter_tags, axis= 1)) & (osm_handle.feature_df['type'] != 'node')]\n",
    "\n",
    "    # for these selected feature we calcuate where aplicable either are or length or both\n",
    "    # and then split them into thier key value pairs\n",
    "    if len(selected_geom_df) > 0:\n",
    "        for element in selected_geom_df[['geometry','tags']].apply(calcualte_size_for_tags,axis=1).tolist():\n",
    "\n",
    "            for key_val in element.keys():\n",
    "                key,value = key_val.split(' ')\n",
    "                _dict = {'key':key,'value':value,'area':element[key_val].get('area'),'length':element[key_val].get('length')}\n",
    "                results_df = results_df.append(_dict,ignore_index=True)\n",
    "\n",
    "        # making shure everything that needs to be pyton None is None\n",
    "        results_df = results_df.where(pd.notnull(results_df), None)\n",
    "\n",
    "    print(f'finished iteration {i} so far we grabbed {len(results_df)} features')\n",
    "    \n",
    "# here we group the differen key value pairs together with the values we fetched from OSM\n",
    "results_grouped_df = results_df.groupby(['key','value']).apply(agg_len_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_grouped_df.to_pickle('./tag_sizes_df.pickle')\n",
    "results_grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "annoying-special",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"16.401891818202394 48.1541888782412 0.005399999999998073 0.005400000000001626\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,96.31377775648241)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00010800000000003251\" opacity=\"0.6\" d=\"M 16.402091818202393,48.1543888782412 L 16.407091818202392,48.1543888782412 L 16.407091818202392,48.1593888782412 L 16.402091818202393,48.1593888782412 L 16.402091818202393,48.1543888782412 z\" /></g></svg>"
      ],
      "text/plain": [
       "<shapely.geometry.polygon.Polygon at 0x7f75cc4b5d60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyleaflet\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles, GeoJSON, WKTLayer\n",
    "from ipywidgets import Label\n",
    "\n",
    "# osmid = test.feature_df[test.feature_df['type']=='relation'].sample().iloc[0]['id']\n",
    "# test_multi = test.generate_geometry('relation',osmid)\n",
    "\n",
    "m = Map(\n",
    "    basemap=basemaps.CartoDB.Positron,\n",
    "    # for some reason lat lon are switch for centering the map\n",
    "    center=(r_bb.centroid.coords[0]),\n",
    "    zoom=14\n",
    ")\n",
    "\n",
    "wlayer = WKTLayer(\n",
    "    wkt_string=r_bb.wkt,\n",
    "    #hover_style={\"fillColor\": \"red\"},\n",
    "    fill_color=\"red\",\n",
    "    color=\"red\",\n",
    ")\n",
    "\n",
    "wlayer2 = WKTLayer(\n",
    "    wkt_string=Polygon([(cord[1],cord[0]) for cord in q_poly.exterior.coords]).wkt,\n",
    "    #hover_style={\"fillColor\": \"red\"},\n",
    "\n",
    ")\n",
    "\n",
    "label = Label()\n",
    "display(label)\n",
    "\n",
    "\n",
    "\n",
    "def handle_interaction(**kwargs):\n",
    "    cords = '[]'\n",
    "    if kwargs.get('type') == 'click':\n",
    "        cords = f'{cords[:-1]}({kwargs.get(\"coordinates\")[0]},{kwargs.get(\"coordinates\")[1]})]'\n",
    "        label.value = cords\n",
    "\n",
    "m.on_interaction(handle_interaction)\n",
    "\n",
    "\n",
    "m.add_layer(wlayer)\n",
    "m.add_layer(wlayer2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
