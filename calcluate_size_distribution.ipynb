{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "advised-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The idea of this script is calculate size distrbutions of osm Features \n",
    "# of intresset is to calculate a distrbution for each key value pair that is \n",
    "# listed on the wikipages refrences in osm_groups.txt\n",
    "# for this we will randomly querry the whole OSM dataset to collect samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "equal-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gis.stackexchange.com/questions/127427/transforming-shapely-polygon-and-multipolygon-objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wanted-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parse_osm\n",
    "from shapely.geometry import Polygon, LineString, Point, MultiPolygon, MultiLineString, MultiPoint\n",
    "from shapely.ops import transform\n",
    "import random\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pyproj\n",
    "import numpy as np\n",
    "import fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "practical-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_bb(size,constrain=None):\n",
    "    # size has to be in degrees since to BB for osm is in degrees\n",
    "    # constrain has to be a shapely (multi-)polygon and can be used to limit the area\n",
    "    \n",
    "    # if a constrain exist we shrink the possibility space donw to the bounds of it \n",
    "    if constrain:\n",
    "        minx, miny, maxx, maxy = constrain.bounds\n",
    "    else:\n",
    "        minx, miny, maxx, maxy = -180,-90,180,90\n",
    "    \n",
    "    # we generate first the lower left corner of the bounding box\n",
    "    if constrain:\n",
    "        # when an constrain exist we make shure the point is within it\n",
    "        ll_x,ll_y =-9999999,-9999999\n",
    "        while not constrain.contains(Point(ll_x, ll_y)):\n",
    "            ll_x,ll_y = random.uniform(minx, maxx),random.uniform(miny, maxy)\n",
    "    else:\n",
    "        ll_x,ll_y = random.uniform(minx, maxx),random.uniform(miny, maxy)\n",
    "        \n",
    "    \n",
    "     \n",
    "    return Polygon([(ll_x,ll_y),(ll_x+size,ll_y),(ll_x+size,ll_y+size),(ll_x,ll_y+size)])\n",
    "    \n",
    "    \n",
    "def generate_tag_list(df):\n",
    "    tag_list = []\n",
    "    for row in df.iterrows():\n",
    "        tag_list.append(f\"{row[1]['key']} {row[1]['value']}\")\n",
    "    \n",
    "    return tag_list\n",
    "\n",
    "\n",
    "def filter_tags(row):\n",
    "    # this function looks if key,value are present in the tag_list \n",
    "    # if so it returns true\n",
    "    r_value = False\n",
    "    if row['tags']:\n",
    "        for key in row['tags'].keys():\n",
    "            if f\"{key} {row['tags'][key]}\" in tag_list:\n",
    "                 r_value = True\n",
    "    return r_value\n",
    "\n",
    "\n",
    "def line_length(line):\n",
    "    \n",
    "    geod = pyproj.Geod(ellps='WGS84')\n",
    "    line_length = geod.geometry_length(line)\n",
    "\n",
    "    return abs(line_length)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def poly_area(poly):\n",
    "\n",
    "    geod = pyproj.Geod(ellps='WGS84')\n",
    "    poly_area = geod.geometry_area_perimeter(poly)[0]\n",
    "    \n",
    "    return abs(poly_area)\n",
    "\n",
    "\n",
    "def calcualte_size_for_tags(row):\n",
    "    \n",
    "    geometry, tags, name  = row['geometry'], row['tags'] , row.name\n",
    "    sizes_dict = {}\n",
    "    # it seems that sometimes the geometry for a feater can not be resolved\n",
    "    # then this\n",
    "    try:\n",
    "        for key in geometry.keys():\n",
    "            if 'line' in key:\n",
    "                sizes_dict['length'] = line_length(geometry[key])\n",
    "            elif 'poly' in key:\n",
    "                sizes_dict['area'] = poly_area(geometry[key])\n",
    "    except:\n",
    "        print(f'geometry could not be resolved for {name}')\n",
    "        sizes_dict['area'] = None\n",
    "            \n",
    "    # we only keep tag key combinations that are part of tag_list     \n",
    "    key_val_list = [f'{key} {tags[key]}' for key in tags.keys() if f'{key} {tags[key]}' in tag_list]\n",
    "    \n",
    "    return_dict = {}\n",
    "    \n",
    "    # a geometry might have more than one relevant tag\n",
    "    # {'tag_key':{'length':,'area':},'tag_key2':{'length':,'area':}}\n",
    "    for key_val in key_val_list:\n",
    "        return_dict[key_val] = sizes_dict\n",
    "\n",
    "    return return_dict\n",
    "\n",
    "\n",
    "def flip_xy(x,y):\n",
    "    return y,x\n",
    "\n",
    "\n",
    "def agg_len_area(x):\n",
    "    length = [el for el in x['length'].tolist() if el]\n",
    "    area = [el for el in x['area'].tolist() if el]\n",
    "    \n",
    "    return pd.Series({'area':area,'length':length}, index=['area', 'length'])\n",
    "\n",
    "\n",
    "def select_ways_and_relations(df):\n",
    "    \n",
    "    if (not 'way' in df.index) and (not 'relation' in df.index):\n",
    "        # if there are neither way nor relation in the df we produce an empty df\n",
    "        selected_df = df.iloc[0:0]    \n",
    "    \n",
    "    elif not 'relation' in df.index:\n",
    "        selected_df = df.loc[['way']]\n",
    "    \n",
    "    elif not 'way' in df.index:\n",
    "        selected_df = df.loc[['relation']]\n",
    "    \n",
    "    else:\n",
    "        selected_df = df.loc[['way','relation']]\n",
    "    \n",
    "    return selected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "applicable-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameters\n",
    "# this sets how many itterations we will go for \n",
    "n_iter = 1000\n",
    "\n",
    "# we can define an area in which we ware looking for key value combinations\n",
    "# if this is not supplied the whole world will be querried\n",
    "# polygon can be arbitrarie (must be in degrees) but only the lower left corner of the random bounding box\n",
    "# is quaranteete to be within the polygon\n",
    "#q_poly = Polygon([(52.450425727741,13.286182880402),(52.458323725344,13.286182880402),(52.458323725344,13.299744129181),(52.450425727741,13.299744129181)])\n",
    "# level_1_admin = gpd.read_file(\"../data/shapes/level_1_admin/ne_10m_admin_1_states_provinces.shp\")\n",
    "# # in this case we select vienna as the polyon\n",
    "# q_poly  = level_1_admin[level_1_admin['name']=='Wien']['geometry'].iloc[0]\n",
    "\n",
    "\n",
    "level_0_admin = gpd.read_file(\"../data/shapes/level_0_admin/ne_10m_admin_0_countries.shp\")\n",
    "# in this case we select vienna as the polyon\n",
    "q_poly  = level_0_admin[level_0_admin['NAME']=='Austria']['geometry'].iloc[0]\n",
    "# x,y need to be fliped because in the loaded shape x == lon y == lat \n",
    "# but overpass wants this to be the other way around\n",
    "# q_poly\n",
    "# here we define the size of our random bounding box in degrees\n",
    "# 0.001Â° =111 m\n",
    "bb_size = 0.005\n",
    "\n",
    "# now we load the predefined tags from pickle\n",
    "tag_df =  pd.read_pickle('./kv_df_just_eng.pickle')\n",
    "tag_list = generate_tag_list(tag_df)\n",
    "\n",
    "# we need the results_df to collect all the values\n",
    "results_df = pd.DataFrame(columns=['key','value','area','length']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "normal-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished iteration 0 so far we grabbed 12 features\n",
      "next open slot in 2 seconds waiting till then\n",
      "next open slot in 4 seconds waiting till then\n",
      "next open slot in 13 seconds waiting till then\n",
      "next open slot in 15 seconds waiting till then\n",
      "next open slot in 17 seconds waiting till then\n",
      "next open slot in 6 seconds waiting till then\n",
      "next open slot in 4 seconds waiting till then\n",
      "next open slot in 4 seconds waiting till then\n",
      "next open slot in 7 seconds waiting till then\n",
      "next open slot in 4 seconds waiting till then\n",
      "next open slot in 7 seconds waiting till then\n",
      "next open slot in 3 seconds waiting till then\n",
      "next open slot in 12 seconds waiting till then\n",
      "next open slot in 2 seconds waiting till then\n",
      "next open slot in 4 seconds waiting till then\n",
      "next open slot in 2 seconds waiting till then\n",
      "next open slot in 2 seconds waiting till then\n",
      "next open slot in 2 seconds waiting till then\n",
      "next open slot in 3 seconds waiting till then\n",
      "next open slot in 2 seconds waiting till then\n",
      "next open slot in 2 seconds waiting till then\n",
      "next open slot in 1 seconds waiting till then\n",
      "next open slot in 12 seconds waiting till then\n",
      "next open slot in 1 seconds waiting till then\n",
      "next open slot in 7 seconds waiting till then\n",
      "next open slot in 39 seconds waiting till then\n",
      "next open slot in 1 seconds waiting till then\n",
      "next open slot in 13 seconds waiting till then\n",
      "next open slot in 1 seconds waiting till then\n",
      "finished iteration 100 so far we grabbed 2137 features\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-654987609221>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# we use the generated polygon to querry osm for all features within the bounding box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mosm_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_osm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisect_osm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_osm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_from_osm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_bb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# and filter the querried polygons for a) if a tag from the tag_list is pressent and b) if they are not just a point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/spatial_semantics/parse_osm.py\u001b[0m in \u001b[0;36mjson_from_osm\u001b[0;34m(poly, mode, key, value, operand)\u001b[0m\n\u001b[1;32m     79\u001b[0m             '''\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mrespones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverpass_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrespones\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/spatial_semantics/parse_osm.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(overpass_url, query)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mrespones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverpass_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m'The server is probably too busy to handle your request'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrespones\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;31m# server seems to be busy we wait for a second\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# and try again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mtext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;31m# Fallback to auto-detected encoding.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapparent_encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;31m# Decode unicode from given encoding.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mapparent_encoding\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapparent_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;34m\"\"\"The apparent encoding, provided by the chardet library.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mchardet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_unicode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/chardet/__init__.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(byte_str)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mbyte_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUniversalDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/chardet/universaldetector.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_charset_probers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLatin1Prober\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mprober\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_charset_probers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProbingState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFOUND_IT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m                     self.result = {'encoding': prober.charset_name,\n\u001b[1;32m    213\u001b[0m                                    \u001b[0;34m'confidence'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_confidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/chardet/charsetgroupprober.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/chardet/sjisprober.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                     self.context_analyzer.feed(byte_str[i + 1 - char_len:i + 3\n\u001b[0m\u001b[1;32m     76\u001b[0m                                                         - char_len], char_len)\n\u001b[1;32m     77\u001b[0m                     self.distribution_analyzer.feed(byte_str[i - 1:i + 1],\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/chardet/jpcntx.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, byte_str, num_bytes)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_need_to_skip_char_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mchar_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/chardet/jpcntx.py\u001b[0m in \u001b[0;36mget_order\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_charset_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mget_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbyte_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(n_iter):\n",
    "    r_bb = random_bb(bb_size,q_poly)\n",
    "#     r_bb = Polygon([(16.366605567347907, 48.145976748430115),\n",
    "#  (16.371605567347906, 48.145976748430115),\n",
    "#  (16.371605567347906, 48.15097674843012),\n",
    "#  (16.366605567347907, 48.15097674843012),\n",
    "#  (16.366605567347907, 48.145976748430115)])\n",
    "\n",
    "    # we use the generated polygon to querry osm for all features within the bounding box\n",
    "    osm_handle = parse_osm.disect_osm(parse_osm.json_from_osm(r_bb))\n",
    "\n",
    "    # and filter the querried polygons for a) if a tag from the tag_list is pressent and b) if they are not just a point\n",
    "    ways_relations_df = select_ways_and_relations(osm_handle.feature_df)\n",
    "    selected_tags_df = ways_relations_df[ways_relations_df.apply(filter_tags, axis= 1)]\n",
    "    type_id_list = selected_tags_df.index.tolist()\n",
    "    # for the selected features we calculate the geometry:\n",
    "    [osm_handle.get_geometry(f_type,osm_id) for f_type, osm_id in type_id_list]\n",
    "    \n",
    "    # reselect to fetch the generated geometries\n",
    "    ways_relations_df = select_ways_and_relations(osm_handle.feature_df)\n",
    "        \n",
    "    selected_tags_df = ways_relations_df[ways_relations_df.apply(filter_tags, axis= 1)]\n",
    "    \n",
    "    # for these selected feature we calcuate where aplicable either area, length or both\n",
    "    # and then split them into thier key value pairs\n",
    "    if len(selected_tags_df) > 0:\n",
    "        for element in selected_tags_df[['geometry','tags']].apply(calcualte_size_for_tags,axis=1).tolist():\n",
    "\n",
    "            for key_val in element.keys():\n",
    "                key,value = key_val.split(' ')\n",
    "                _dict = {'key':key,'value':value,'area':element[key_val].get('area'),'length':element[key_val].get('length')}\n",
    "                results_df = results_df.append(_dict,ignore_index=True)\n",
    "\n",
    "        # making shure everything that needs to be pyton None is None\n",
    "        results_df = results_df.where(pd.notnull(results_df), None)\n",
    "    if i % 100 == 0:\n",
    "        print(f'finished iteration {i} so far we grabbed {len(results_df)} features')\n",
    "    \n",
    "# here we group the differen key value pairs together with the values we fetched from OSM\n",
    "results_grouped_df = results_df.groupby(['key','value']).apply(agg_len_area).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "experienced-conservative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>area</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amenity</td>\n",
       "      <td>bicycle_parking</td>\n",
       "      <td>[221.11655436083674]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amenity</td>\n",
       "      <td>fast_food</td>\n",
       "      <td>[41.55299437046051]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amenity</td>\n",
       "      <td>fire_station</td>\n",
       "      <td>[228.32604893203825]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amenity</td>\n",
       "      <td>motorcycle_parking</td>\n",
       "      <td>[13.449348604306579]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amenity</td>\n",
       "      <td>parking</td>\n",
       "      <td>[1396.798954024911, 914.6249684542418, 966.481...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>water</td>\n",
       "      <td>pond</td>\n",
       "      <td>[428.1113355057314, 2337.0685060804244, 922.29...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>water</td>\n",
       "      <td>river</td>\n",
       "      <td>[5376236.271423575]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>waterway</td>\n",
       "      <td>ditch</td>\n",
       "      <td>[]</td>\n",
       "      <td>[194.14467825169095, 9.150047251760567, 5.3796...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>waterway</td>\n",
       "      <td>river</td>\n",
       "      <td>[387092.03347870347]</td>\n",
       "      <td>[1123.3764675948669, 242.307452768138, 113177....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>waterway</td>\n",
       "      <td>stream</td>\n",
       "      <td>[]</td>\n",
       "      <td>[5017.5623805798605, 3412.9755964136284, 3257....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          key               value  \\\n",
       "0     amenity     bicycle_parking   \n",
       "1     amenity           fast_food   \n",
       "2     amenity        fire_station   \n",
       "3     amenity  motorcycle_parking   \n",
       "4     amenity             parking   \n",
       "..        ...                 ...   \n",
       "106     water                pond   \n",
       "107     water               river   \n",
       "108  waterway               ditch   \n",
       "109  waterway               river   \n",
       "110  waterway              stream   \n",
       "\n",
       "                                                  area  \\\n",
       "0                                 [221.11655436083674]   \n",
       "1                                  [41.55299437046051]   \n",
       "2                                 [228.32604893203825]   \n",
       "3                                 [13.449348604306579]   \n",
       "4    [1396.798954024911, 914.6249684542418, 966.481...   \n",
       "..                                                 ...   \n",
       "106  [428.1113355057314, 2337.0685060804244, 922.29...   \n",
       "107                                [5376236.271423575]   \n",
       "108                                                 []   \n",
       "109                               [387092.03347870347]   \n",
       "110                                                 []   \n",
       "\n",
       "                                                length  \n",
       "0                                                   []  \n",
       "1                                                   []  \n",
       "2                                                   []  \n",
       "3                                                   []  \n",
       "4                                                   []  \n",
       "..                                                 ...  \n",
       "106                                                 []  \n",
       "107                                                 []  \n",
       "108  [194.14467825169095, 9.150047251760567, 5.3796...  \n",
       "109  [1123.3764675948669, 242.307452768138, 113177....  \n",
       "110  [5017.5623805798605, 3412.9755964136284, 3257....  \n",
       "\n",
       "[111 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_grouped_df.to_pickle('../data/spatial_semantics/tag_sizes_big_df.pickle')\n",
    "results_grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_tags_df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-covering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(r_bb.exterior.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyleaflet\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles, GeoJSON, WKTLayer\n",
    "from ipywidgets import Label\n",
    "\n",
    "# osmid = test.feature_df[test.feature_df['type']=='relation'].sample().iloc[0]['id']\n",
    "# test_multi = test.get_geometry('relation',osmid)\n",
    "\n",
    "m = Map(\n",
    "    basemap=basemaps.CartoDB.Positron,\n",
    "    # for some reason lat lon are switch for centering the map\n",
    "    center=(r_bb.centroid.coords[0][1],r_bb.centroid.coords[0][0]),\n",
    "    zoom=14\n",
    ")\n",
    "\n",
    "wlayer = WKTLayer(\n",
    "    wkt_string=r_bb.wkt,\n",
    "    #hover_style={\"fillColor\": \"red\"},\n",
    "    fill_color=\"red\",\n",
    "    color=\"red\",\n",
    ")\n",
    "\n",
    "\n",
    "m.add_layer(wlayer)\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
