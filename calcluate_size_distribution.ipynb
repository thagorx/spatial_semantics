{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "silver-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The idea of this script is calculate size distrbutions of osm Features \n",
    "# of intresset is to calculate a distrbution for each key value pair that is \n",
    "# listed on the wikipages refrences in osm_groups.txt\n",
    "# for this we will randomly querry the whole OSM dataset to collect samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hungarian-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gis.stackexchange.com/questions/127427/transforming-shapely-polygon-and-multipolygon-objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sophisticated-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parse_osm\n",
    "import tag_handler\n",
    "from shapely.geometry import Polygon, LineString, Point, MultiPolygon, MultiLineString, MultiPoint\n",
    "from shapely.ops import transform\n",
    "import random\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pyproj\n",
    "import numpy as np\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alleged-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_len_area(x):\n",
    "    length = [el for el in x['length'].tolist() if el]\n",
    "    area = [el for el in x['area'].tolist() if el]\n",
    "    \n",
    "    return pd.Series({'area':area,'length':length}, index=['area', 'length'])\n",
    "\n",
    "\n",
    "def select_ways_and_relations(df):\n",
    "    \n",
    "    if (not 'way' in df.index) and (not 'relation' in df.index):\n",
    "        # if there are neither way nor relation in the df we produce an empty df\n",
    "        selected_df = df.iloc[0:0]    \n",
    "    \n",
    "    elif not 'relation' in df.index:\n",
    "        selected_df = df.loc[['way']]\n",
    "    \n",
    "    elif not 'way' in df.index:\n",
    "        selected_df = df.loc[['relation']]\n",
    "    \n",
    "    else:\n",
    "        selected_df = df.loc[['way','relation']]\n",
    "    \n",
    "    return selected_df\n",
    "\n",
    "\n",
    "def calc_median(values):\n",
    "    #print(values)\n",
    "    median_v = None\n",
    "    if values:\n",
    "        median_v = statistics.median(values)\n",
    "    return median_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "joint-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameters\n",
    "# this sets how many itterations we will go for \n",
    "n_iter = 10\n",
    "\n",
    "\n",
    "# we can define an area in which we ware looking for key value combinations\n",
    "# if this is not supplied the whole world will be querried\n",
    "# polygon can be arbitrarie (must be in degrees) but only the lower left corner of the random bounding box\n",
    "# is quaranteete to be within the polygon\n",
    "# q_poly = Polygon([(52.450425727741,13.286182880402),(52.458323725344,13.286182880402),(52.458323725344,13.299744129181),(52.450425727741,13.299744129181)])\n",
    "\n",
    "level_1_admin = gpd.read_file(\"../data/shapes/level_1_admin/ne_10m_admin_1_states_provinces.shp\")\n",
    "# in this case we select vienna as the polyon\n",
    "q_poly  = level_1_admin[level_1_admin['name']=='Wien']['geometry'].iloc[0]\n",
    "\n",
    "\n",
    "#level_0_admin = gpd.read_file(\"../data/shapes/level_0_admin/ne_10m_admin_0_countries.shp\")\n",
    "# in this case we select vienna as the polyon\n",
    "#q_poly  = level_0_admin[level_0_admin['NAME']=='Austria']['geometry'].iloc[0]\n",
    "# x,y need to be fliped because in the loaded shape x == lon y == lat \n",
    "# but overpass wants this to be the other way around\n",
    "# q_poly\n",
    "# here we define the size of our random bounding box in degrees\n",
    "# 0.001Â° =111 m\n",
    "bb_size = 0.005\n",
    "\n",
    "# now we load the predefined tags from pickle\n",
    "\n",
    "tag_df =  pd.read_pickle('../data/spatial_semantics/kv_df_just_eng.pickle')\n",
    "filtertags_handler = tag_handler.filtertags(tag_df)\n",
    "\n",
    "# tag_list = tag_handler.generate_tag_list(tag_df)\n",
    "\n",
    "# we need the results_df to collect all the values\n",
    "results_df = pd.DataFrame(columns=['key','value','area','length']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "desirable-functionality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished iteration 0 so far we grabbed 110 features\n",
      "finished iteration 1 so far we grabbed 112 features\n",
      "next open slot in 50 seconds waiting till then\n",
      "finished iteration 2 so far we grabbed 116 features\n",
      "finished iteration 3 so far we grabbed 411 features\n",
      "finished iteration 4 so far we grabbed 426 features\n",
      "next open slot in 8 seconds waiting till then\n",
      "finished iteration 5 so far we grabbed 644 features\n",
      "next open slot in 62 seconds waiting till then\n",
      "finished iteration 6 so far we grabbed 748 features\n",
      "next open slot in 10 seconds waiting till then\n",
      "finished iteration 7 so far we grabbed 752 features\n",
      "next open slot in 30 seconds waiting till then\n",
      "finished iteration 8 so far we grabbed 938 features\n",
      "next open slot in 8 seconds waiting till then\n",
      "finished iteration 9 so far we grabbed 1368 features\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_iter):\n",
    "    r_bb = tag_handler.random_bb(bb_size,q_poly)\n",
    "#     r_bb = Polygon([(16.366605567347907, 48.145976748430115),\n",
    "#  (16.371605567347906, 48.145976748430115),\n",
    "#  (16.371605567347906, 48.15097674843012),\n",
    "#  (16.366605567347907, 48.15097674843012),\n",
    "#  (16.366605567347907, 48.145976748430115)])\n",
    "\n",
    "    # we use the generated polygon to querry osm for all features within the bounding box\n",
    "    osm_handle = parse_osm.disect_osm(parse_osm.json_from_osm(r_bb))\n",
    "\n",
    "    # and filter the querried polygons for a) if a tag from the tag_list is pressent and b) if they are not just a point\n",
    "    ways_relations_df = select_ways_and_relations(osm_handle.feature_df)\n",
    "    selected_tags_df = ways_relations_df[ways_relations_df.apply(filtertags_handler.filter_them, axis = 1)]\n",
    "    type_id_list = selected_tags_df.index.tolist()\n",
    "    # for the selected features we calculate the geometry:\n",
    "    [osm_handle.get_geometry(f_type,osm_id) for f_type, osm_id in type_id_list]\n",
    "    \n",
    "    # reselect to fetch the generated geometries\n",
    "    ways_relations_df = select_ways_and_relations(osm_handle.feature_df)\n",
    "        \n",
    "    selected_tags_df = ways_relations_df[ways_relations_df.apply(filtertags_handler.filter_them, axis= 1)]\n",
    "    \n",
    "    # for these selected feature we calcuate where aplicable either area, length or both\n",
    "    # and then split them into thier key value pairs\n",
    "    if len(selected_tags_df) > 0:\n",
    "        for element in selected_tags_df[['geometry','tags']].apply(filtertags_handler.calcualte_size_for_tags, axis=1).tolist():\n",
    "\n",
    "            for key_val in element.keys():\n",
    "                key,value = key_val.split(' ')\n",
    "                _dict = {'key':key,'value':value,'area':element[key_val].get('area'),'length':element[key_val].get('length')}\n",
    "                results_df = results_df.append(_dict,ignore_index=True)\n",
    "\n",
    "        # making shure everything that needs to be pyton None is None\n",
    "        results_df = results_df.where(pd.notnull(results_df), None)\n",
    "    if i % 1 == 0:\n",
    "        print(f'finished iteration {i} so far we grabbed {len(results_df)} features')\n",
    "    \n",
    "# here we group the differen key value pairs together with the values we fetched from OSM\n",
    "results_grouped_df = results_df.groupby(['key','value']).apply(agg_len_area).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for easy access we calculat the median for area and value for each key value pair\n",
    "results_grouped_df['median_area'] = results_grouped_df['area'].apply(calc_median)\n",
    "results_grouped_df['median_length'] = results_grouped_df['length'].apply(calc_median)\n",
    "results_grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_grouped_df.to_pickle('../data/spatial_semantics/tag_sizes_median_df.pickle')\n",
    "results_grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_tags_df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next todos:\n",
    "# construct a vector for one bounding box\n",
    "#    - fetch all the features within a bb (allready works) [x]\n",
    "#    - wheig the features according to their median size in sample dataset\n",
    "#    - feed words acording to weiths into a document \n",
    "#    - generate a vector for this document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch all features and fitler "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
